
<!DOCTYPE html>
<html>
<head>
    <title>Smileyan</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">
    <link href="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
    <script src="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
    
<link rel="stylesheet" href="../../../css/prism.css">
 
    
<script src="../../../js/prism.js"></script>

    
    
<link rel="stylesheet" href="../../../css/index.css">
 
    
<script src="../../../js/search.js"></script>



     
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
        </script>
     

     
        <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"> </script>
        
<script src="../../../js/fancybox.js"></script>

    

    <script type="text/javascript">
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
        var path = "/" + search_path;
        searchFunc(path, 'local-search-input', 'local-search-result');
    </script>
<meta name="generator" content="Hexo 5.4.2"></head>
 
 
<body>
    <!-- 导航栏 -->
    <!-- 导航栏 -->
<nav class="navbar navbar-expand-md navbar-dark bg-dark mb-4 pt-2 pb-2">
    <div class="container">
        <!-- 标题 --> 
        <a class="navbar-brand navbar-expand-sm" href="/">
            <img class="nofancybox" src="/logo.png" style="width: 75px;"  alt="笑颜网">
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <!-- 左边右边导航按钮 --> 
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto">
                <!-- 左右两侧的导航栏 -->

 
 

    <li class="nav-item">
        <a class="nav-link" href="../../../">
           <big> <i class="fa fa-home ps-1" ></i> 主页</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../archives">
           <big> <i class="fa fa-archive ps-1" ></i> 归档</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../about">
           <big> <i class="fa fa-user ps-1" ></i> 关于</big>
        </a>
    </li>
 
 
            </ul>

            
            <form class="">
                <div class="d-flex">
                    <button class="btn text-muted fa fa-search d-none d-md-block d-lg-block" disabled></button>
                    <input id="local-search-input" class="form-control me-2 pe-4" type="search"
                            placeholder="搜索 " aria-label="Search">
                </div>
                <div id="local-search-result" style="position:absolute; padding-top: 8px; max-height: 960px; width: 480px;overflow-y: scroll; z-index: 1050;"></div>
            </form>
            
            <ul class="navbar-nav">
                <!-- 左右两侧的导航栏 -->

 
 
            </ul>
        </div>
    </div>
</nav>


    <main class="container">
        
<div class="container-fluid markdown-section">
<div class="row">
    <div class="col-md-2 d-none d-sm-none d-md-block">
        <div class="">
            <!-- 同一类型的文件 -->
<!-- 尽可能做到每篇文章只有一个类
    1. 获得 post 的类别 categories
     2.1 如果 categories.length === 0，啥也不做
     2.2 如果 categories === 1，渲染这个类的所有文章
     2.3 如果 categories.length > 1 ，则以第一个类为准渲染所有文章
-->


 
        </div>
    </div>
    <div class="col-md-8 col-sm-12">
        <!-- 博客详情 -->
        <div class="">
            <!-- ps-4 pe-4 pt-2 -->
            <p class="h2">
                <span class="post-title">
                    Self-supervised learning survey
                </span>   
            </p>

            <div class="pb-3 pt-1 pe-3">
                <i class="fa fa-calendar p-1"></i>
                2020/07/30 15:00:00 

                <i class="fa fa-pencil"> </i>
                2022/04/12 19:26:55 

                <!--
                <i class="fa fa-folder-open p-1"> </i> 
                <span class="tag-hover">
                     
                </span>
                -->

                <i class="fa fa-tags p-1"> </i>
                <span class="tag-hover">
                    
                        <a href="../../../tags/note/" class="link-dark text-decoration-none"> 
                            note 
                        </a>
                    
                        <a href="../../../tags/self-supervised-learning/" class="link-dark text-decoration-none"> 
                            self-supervised learning 
                        </a>
                    
                </span>
            </div>

            <div class="border-bottom pb-2">
                <h1 id="Survey-Self-supervised-learning-Generative-or-Contrastive"><a href="#Survey-Self-supervised-learning-Generative-or-Contrastive" class="headerlink" title="Survey: Self-supervised learning: Generative or Contrastive"></a>Survey: Self-supervised learning: Generative or Contrastive</h1><p>清华唐杰团队的工作，比较完整。</p>
<p><a target="_blank" rel="noopener" href="https://www.aliyundrive.com/s/Hf99EegM1pd">PDF FILE (包含一些笔记)</a></p>
<span id="more"></span>

<hr>
<p>自监督任务的方法共分为3类，分别为生成式（generative）、判别式（contrastive）、对抗式（generative-contrastive (adversarial)），他们的区别如下。</p>
<img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img_profile/20200730194624.png" alt="compare" style="zoom:67%;" />

<h2 id="GENERATIVE-SELF-SUPERVISED-LEARNING"><a href="#GENERATIVE-SELF-SUPERVISED-LEARNING" class="headerlink" title="GENERATIVE SELF-SUPERVISED LEARNING"></a>GENERATIVE SELF-SUPERVISED LEARNING</h2><h3 id="Auto-regressive-AR-Model"><a href="#Auto-regressive-AR-Model" class="headerlink" title="Auto-regressive (AR) Model"></a>Auto-regressive (AR) Model</h3><ul>
<li><p>pros: The advantage of auto-regressive models is that it can model the context dependency well.</p>
</li>
<li><p>cons: However, one shortcoming of the AR model is that the token at each position can only access its context from one direction.</p>
</li>
</ul>
<h3 id="Flow-based-Model"><a href="#Flow-based-Model" class="headerlink" title="Flow-based Model"></a>Flow-based Model</h3><h3 id="Auto-encoding-AE-Model"><a href="#Auto-encoding-AE-Model" class="headerlink" title="Auto-encoding (AE) Model"></a>Auto-encoding (AE) Model</h3><ol>
<li>Basic AE Model</li>
<li>Context Prediction Model (CPM): The idea of the Context Prediction Model (CPM) is predicting contextual information based on inputs.</li>
<li>The idea of denoising autoencoder models is that representation should be robust to the introduction of noise. The masked language model (MLM) can be regarded as a denoising because its input masks predicted tokens.</li>
<li>Variational AE Model</li>
</ol>
<h3 id="Hybrid-Generative-Models"><a href="#Hybrid-Generative-Models" class="headerlink" title="Hybrid Generative Models"></a>Hybrid Generative Models</h3><ol>
<li>Combining AR and AE Model.</li>
<li>Combining AE and Flow-based Models</li>
</ol>
<h2 id="CONTRASTIVE-SELF-SUPERVISED-LEARNING-Contrastive-learning-aims-at-“learn-to-compare”"><a href="#CONTRASTIVE-SELF-SUPERVISED-LEARNING-Contrastive-learning-aims-at-“learn-to-compare”" class="headerlink" title="CONTRASTIVE SELF-SUPERVISED LEARNING: Contrastive learning aims at “learn to compare”."></a>CONTRASTIVE SELF-SUPERVISED LEARNING: Contrastive learning aims at “learn to compare”.</h2><h3 id="context-instance-contrast-即对比某个样本及其它的语境"><a href="#context-instance-contrast-即对比某个样本及其它的语境" class="headerlink" title="context-instance contrast: 即对比某个样本及其它的语境"></a>context-instance contrast: 即对比某个样本及其它的语境</h3><ol>
<li>Predict Relative Position (PRP): 直观的理解，是将原始数据的好几个部分用某种方式打乱，然后使用一个辅助的任务尝试恢复原有的数据。</li>
</ol>
<p>例：在CV中，将某个样本，a) 分割成几个部分，然后打乱顺序，附加任务为恢复顺序；b) 做旋转，附加任务是将旋转后的样本恢复；c) 分割后完成一个拼图游戏。</p>
<img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img_profile/20200730193851.png" style="zoom:67%;" />

<ol start="2">
<li>Maximize Mutual Information：直观来讲，即使用互信息来表征某个instance是否属于一个context，给定一个context-instance pair，并给定其是否属于同一个样本的标签（0：不属于，1：属于），则最小化正样本的互信息，并最大化负样本的互信息。</li>
</ol>
<p>cons: The [132] provides empirical evidence that the success of the models mentioned above is only loosely connected to MI by showing that an upper bound MI estimator leads to ill-conditioned and lower performance representation. Instead, more should be attributed to encoder architecture and a negative sampling strategy related to metric learning.</p>
<blockquote>
<p>Some examples:</p>
<p><strong>(CV)</strong> maximize the MI between a local patch and its global context.</p>
<p><strong>(speech)</strong> CPC maximize the association between a segment of audio and its context audio.</p>
<p><strong>(NLP)</strong> maximize the mutual information between a global representation of a sentence and n-grams in it.</p>
<p><strong>(Graph)</strong> Deep Graph InfoMax (DGI) [139] considers a node’s representation as the local feature and the average of randomly samples 2-hop neighbors as context.</p>
</blockquote>
<h3 id="context-context-contrast-即对比两个独立的样本"><a href="#context-context-contrast-即对比两个独立的样本" class="headerlink" title="context-context contrast: 即对比两个独立的样本"></a>context-context contrast: 即对比两个独立的样本</h3><p>对于一个样本，首先生成他的多个副本（通过各种加噪/数据增强的方式），然后最小化这几个样本之间的相似度，并最大化这些样本与另一个独立样本的相似度。<br>例：在cv中，多个副本是通过裁剪、颜色转换、旋转等方式生成的。</p>
<img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img_profile/20200730194302.png" style="zoom: 67%;" />
        
<h2 id="GENERATIVE-CONTRASTIVE-ADVERSARIAL-SELF-SUPERVISED-LEARNING"><a href="#GENERATIVE-CONTRASTIVE-ADVERSARIAL-SELF-SUPERVISED-LEARNING" class="headerlink" title="GENERATIVE-CONTRASTIVE (ADVERSARIAL) SELF-SUPERVISED LEARNING"></a>GENERATIVE-CONTRASTIVE (ADVERSARIAL) SELF-SUPERVISED LEARNING</h2><p>pros: 1) A reason for the generative model’s success in self-supervised learning is its ability to fit the data distribution. 2) GANs are designed to serve for human-level understanding. 3) GANs focus on capturing the complete information of the sample.</p>
<ol>
<li><p>Generate with Complete Input: 将完整的样本送入网络并进行压缩与重建，由discriminator判别重建数据与原始数据的差异。</p>
</li>
<li><p>Recover with Partial Input: 将经过处理（加噪、转换）的样本送入网络进行重建，由discriminator判别重建数据与原始完整数据的差异。从这个角度上来讲，与判别式方法非常像，但是二者学习分布的方式不同，discriminator的复杂度也不同。</p>
</li>
</ol>
<img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img_profile/20200730195129.png" style="zoom: 50%;" />


 
            </div>
        </div>
        
        <div class="mt-3">
            <!-- 前一页后一页 -->
<div class="previous-next-links">
     
    <div class="previous-design-link">
        <a href="../../paperlistfile/KDD2020/">
            <i style="font-size:16px;" class="fa fa-arrow-left" aria-hidden="true"></i>
            Related Papers in SIGKDD 2020 (2020.08.23)
        </a>
    </div>
     

     
    <div class="next-design-link">
        <a href="../../paperlistfile/SIGIR2020/">
            Related Papers in SIRIR 2020 (2020.07.25)
            <i style="font-size:16px;" class="fa fa-arrow-right" aria-hidden="true"></i>
        </a>
    </div>
 
</div> 
             
        </div>

    </div>
    <div class="col-2">
        <div class="d-none d-sm-none d-md-block sticky-top border-start">
             
    
        <div>
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Survey-Self-supervised-learning-Generative-or-Contrastive"><span class="toc-number">1.</span> <span class="toc-text">Survey: Self-supervised learning: Generative or Contrastive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#GENERATIVE-SELF-SUPERVISED-LEARNING"><span class="toc-number">1.1.</span> <span class="toc-text">GENERATIVE SELF-SUPERVISED LEARNING</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Auto-regressive-AR-Model"><span class="toc-number">1.1.1.</span> <span class="toc-text">Auto-regressive (AR) Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flow-based-Model"><span class="toc-number">1.1.2.</span> <span class="toc-text">Flow-based Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Auto-encoding-AE-Model"><span class="toc-number">1.1.3.</span> <span class="toc-text">Auto-encoding (AE) Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hybrid-Generative-Models"><span class="toc-number">1.1.4.</span> <span class="toc-text">Hybrid Generative Models</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CONTRASTIVE-SELF-SUPERVISED-LEARNING-Contrastive-learning-aims-at-%E2%80%9Clearn-to-compare%E2%80%9D"><span class="toc-number">1.2.</span> <span class="toc-text">CONTRASTIVE SELF-SUPERVISED LEARNING: Contrastive learning aims at “learn to compare”.</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#context-instance-contrast-%E5%8D%B3%E5%AF%B9%E6%AF%94%E6%9F%90%E4%B8%AA%E6%A0%B7%E6%9C%AC%E5%8F%8A%E5%85%B6%E5%AE%83%E7%9A%84%E8%AF%AD%E5%A2%83"><span class="toc-number">1.2.1.</span> <span class="toc-text">context-instance contrast: 即对比某个样本及其它的语境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#context-context-contrast-%E5%8D%B3%E5%AF%B9%E6%AF%94%E4%B8%A4%E4%B8%AA%E7%8B%AC%E7%AB%8B%E7%9A%84%E6%A0%B7%E6%9C%AC"><span class="toc-number">1.2.2.</span> <span class="toc-text">context-context contrast: 即对比两个独立的样本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GENERATIVE-CONTRASTIVE-ADVERSARIAL-SELF-SUPERVISED-LEARNING"><span class="toc-number">1.3.</span> <span class="toc-text">GENERATIVE-CONTRASTIVE (ADVERSARIAL) SELF-SUPERVISED LEARNING</span></a></li></ol></li></ol> 
        </div>
    
 

        </div>
    </div>
</div>
</div>
 
    </main>

    <!-- 底部栏 -->
    <footer class="bg-dark pt-1 pb-0 mt-5">
    <div class="container pb-3 pt-3 text-center">
        <p class="text-muted tag-hover">
            All Rights Reserved <i class="fa fa-copyright"></i> 2017-2022 笑颜网 smileyan.cn <br> 
            Powered by 
             <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://hexo.io">
                 Hexo.io
            </a> &  <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://github.com/smile-yan/hexo-theme-heyan">
               heyan
            </a>
            <br>
            <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/#/Integrated/index">
                <img src="/police.png" style="width: 18px; height: 18px; margin-top: -4px" class="nofancybox">
                湘ICP备 17012851号 
            </a>
        </p>
    </div>
</footer>
</body> 
</html>