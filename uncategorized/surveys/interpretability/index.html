
<!DOCTYPE html>
<html>
<head>
    <title> Here is Shaoyu </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="/fish.png" size="16x16">
    <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">
    <link href="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
    <script src="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
    
<link rel="stylesheet" href="../../../css/prism.css">
 
    
<script src="../../../js/prism.js"></script>

    
    
<link rel="stylesheet" href="../../../css/index.css">
 
    
<script src="../../../js/search.js"></script>



     
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
        </script>
     

     
        <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"> </script>
        
<script src="../../../js/fancybox.js"></script>

    

    <script type="text/javascript">
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
        var path = "/" + search_path;
        searchFunc(path, 'local-search-input', 'local-search-result');
    </script>
<meta name="generator" content="Hexo 5.4.2"></head>
 
 
<body>
    <!-- 导航栏 -->
    <!-- 导航栏 -->
<nav class="navbar navbar-expand-md navbar-dark bg-dark mb-4 pt-2 pb-2">
    <div class="container">
        <!-- 标题 --> 
        <a class="navbar-brand navbar-expand-sm" href="/">
            <img class="nofancybox" src="/shark.svg" style="width: 65px;">
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <!-- 左边右边导航按钮 --> 
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto">
                <!-- 左右两侧的导航栏 -->

 
 

    <li class="nav-item">
        <a class="nav-link" href="../../../">
           <big> <i class="fa fa-home ps-1" ></i> Home</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../note">
           <big> <i class="fa fa-file-text-o ps-1" ></i> Notes</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../survey">
           <big> <i class="fa fa-globe ps-1" ></i> Surveys</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../paperlist">
           <big> <i class="fa fa-cc-discover ps-1" ></i> Paper Lists</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../archives">
           <big> <i class="fa fa-archive ps-1" ></i> Archives</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../about">
           <big> <i class="fa fa-user ps-1" ></i> About</big>
        </a>
    </li>
 
 
            </ul>

            
            <form class="">
                <div class="d-flex">
                    <button class="btn text-muted fa fa-search d-none d-md-block d-lg-block" disabled></button>
                    <input id="local-search-input" class="form-control me-2 pe-4" type="search"
                            placeholder="搜索 " aria-label="Search">
                </div>
                <div id="local-search-result" style="position:absolute; padding-top: 8px; max-height: 960px; width: 480px;overflow-y: scroll; z-index: 1050;"></div>
            </form>
            
            <ul class="navbar-nav">
                <!-- 左右两侧的导航栏 -->

 
 
            </ul>
        </div>
    </div>
</nav>


    <main class="container">
        
<div class="container-fluid markdown-section">
<div class="row">
    <div class="col-md-2 d-none d-sm-none d-md-block">
        <div class="">
            <!-- 同一类型的文件 -->
<!-- 尽可能做到每篇文章只有一个类
    1. 获得 post 的类别 categories
     2.1 如果 categories.length === 0，啥也不做
     2.2 如果 categories === 1，渲染这个类的所有文章
     2.3 如果 categories.length > 1 ，则以第一个类为准渲染所有文章
-->


 
        </div>
    </div>
    <div class="col-md-8 col-sm-12">
        <!-- 博客详情 -->
        <div class="">
            <!-- ps-4 pe-4 pt-2 -->
            <p class="h2">
                <span class="post-title">
                    Post-hoc interpretability
                </span>   
            </p>

            <div class="pb-3 pt-1 pe-3">
                <i class="fa fa-calendar p-1"></i>
                2020/12/29 12:00:00 

                <i class="fa fa-pencil"> </i>
                2022/04/12 19:21:26 

                <!--
                <i class="fa fa-folder-open p-1"> </i> 
                <span class="tag-hover">
                     
                </span>
                -->

                <i class="fa fa-tags p-1"> </i>
                <span class="tag-hover">
                    
                        <a href="../../../tags/paper-list/" class="link-dark text-decoration-none"> 
                            paper list 
                        </a>
                    
                        <a href="../../../tags/survey/" class="link-dark text-decoration-none"> 
                            survey 
                        </a>
                    
                        <a href="../../../tags/interpretability/" class="link-dark text-decoration-none"> 
                            interpretability 
                        </a>
                    
                </span>
            </div>

            <div class="border-bottom pb-2">
                <h2 id="研究问题描述"><a href="#研究问题描述" class="headerlink" title="研究问题描述"></a>研究问题描述</h2><p>深度学习模型的事后（post-hoc）可解释方法：给定一个已训练的深度神经网络模型，如何对其输出进行解释。</p>
<span id="more"></span>


<h2 id="领域现状"><a href="#领域现状" class="headerlink" title="领域现状"></a>领域现状</h2><h3 id="基于叠加的方法-Superimposition-based-explanation"><a href="#基于叠加的方法-Superimposition-based-explanation" class="headerlink" title="基于叠加的方法 (Superimposition-based explanation)"></a>基于叠加的方法 (Superimposition-based explanation)</h3><p>  这类方法将网络的输出归因到网络的输入上，显式的指出网络输入中的每个维度对网络输出的贡献程度，</p>
<ul>
<li><p>优点：直观</p>
</li>
<li><p>缺点：有时会生成令人误解的解释，如当网络将已知的无关输入视为重要判断依据时</p>
</li>
</ul>
<p>  [1]LIME：通过对输入施加轻微的扰动，以探测黑盒模型的输出变化，优化一个可解释模型（线性模型或tree-based model）局部近似黑盒模型的预测。</p>
<p>  [2]SHAP：基于博弈理论（shapley value, a game-theory based method），计算网络输入的每一维对网络输出的贡献（也是将黑盒模型做局部近拟，使其具有可解释性）</p>
<p>  [3]saliency map：训练一个遮罩模型（masking model）以识别最影响分类器决断的输入特征。</p>
<p>  [4]Integrated Gradients：以输入特征在某个路径上的梯度积分（ Integrated Gradients ）作为该特征的重要性得分。</p>
<h3 id="基于例子的方法-example-based-explanation"><a href="#基于例子的方法-example-based-explanation" class="headerlink" title="基于例子的方法 (example-based explanation)"></a>基于例子的方法 (example-based explanation)</h3><p>  这类方法针对某个待解释的案例，依照某种策略生成一组案例（a set of example），这组案例一般是支持网络对待解释案例做出判断的主要依据。通过人类直观的对比这组案例与待解释的案例，总结出的差异与共同点将被视为一种直接的解释。</p>
<ul>
<li><p>优点：易于理解</p>
</li>
<li><p>缺点：依赖于训练集的质量与数量</p>
<p>[10]: 通过在训练样本上施加一个微小的扰动，观察该扰动对所训练出的模型权重的影响，以此来确定网络在对给定样本进行预测时，是哪些训练样本起到了决定性作用。</p>
<p>[11]: 搜索给定样本在深度学习模型的每一层特征空间中的最近邻，其邻居构成的合集即为用于解释给定样本的训练集（给定样本与该集合中的样本共性即为他们获得相同标签的原因）。</p>
</li>
</ul>
<hr>
<h2 id="代表性论文10篇"><a href="#代表性论文10篇" class="headerlink" title="代表性论文10篇"></a>代表性论文10篇</h2><h3 id="基于叠加的方法"><a href="#基于叠加的方法" class="headerlink" title="基于叠加的方法"></a>基于叠加的方法</h3><p>  <strong>经典方法</strong></p>
<p>  [1]: Marco Túlio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. “Why Should I Trust You?”: Explaining the Predictions of Any Classifier. In SIGKDD. ACM, 1135–1144. (LIME)</p>
<p>  [2]: Scott M. Lundberg and Su-In Lee. 2017. A Unified Approach to Interpreting Model Predictions. In NeurIPS. 4765–4774. (SHAP)</p>
<p>  [3]: Piotr Dabkowski and Yarin Gal. 2017. Real Time Image Saliency for Black Box Classifiers. In NeurIPS. 6967–6976. (saliency map)</p>
<p>  [4]: Sundararajan, M., Taly, A., &amp; Yan, Q. (2017, August). Axiomatic attribution for deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp. 3319-3328).</p>
<p>  <strong>其他工作</strong></p>
<p>  [5]: Ismail, A., Gunady, M., Bravo, H., &amp; Feizi, S. (2020). Benchmarking Deep Learning Interpretability in Time Series Predictions. Advances in Neural Information Processing Systems Foundation (NeurIPS).</p>
<p>  [6]: Giurgiu, I., &amp; Schumann, A. (2019). Explainable failure predictions with rnn classifiers based on time series data. arXiv preprint arXiv:1901.08554.</p>
<p>  [7]: Mujkanovic, F., Doskoč, V., Schirneck, M., Schäfer, P., &amp; Friedrich, T. (2020). timeXplain–A Framework for Explaining the Predictions of Time Series Classifiers. arXiv preprint arXiv:2007.07606.</p>
<p>  [8]: Nguyen, T. T., Le Nguyen, T., &amp; Ifrim, G. (2020, September). A Model-Agnostic Approach to Quantifying the Informativeness of Explanation Methods for Time Series Classification. In International Workshop on Advanced Analytics and Learning on Temporal Data (pp. 77-94). Springer, Cham.</p>
<p>  [9]: Shankaranarayana, S. M., &amp; Runje, D. (2019, November). ALIME: Autoencoder based approach for local interpretability. In International Conference on Intelligent Data Engineering and Automated Learning (pp. 454-463). Springer, Cham.</p>
<h3 id="基于例子的方法"><a href="#基于例子的方法" class="headerlink" title="基于例子的方法"></a>基于例子的方法</h3><p>  <strong>经典方法</strong></p>
<p>  [10]: Koh, P. W., &amp; Liang, P. (2017, July). Understanding Black-box Predictions via Influence Functions. In International Conference on Machine Learning (pp. 1885-1894).</p>
<p>  [11]: Nicolas Papernot and Patrick McDaniel. Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning. arXiv preprint arXiv:1803.04765, 2018.</p>
<p>  <strong>其他工作</strong></p>
<p>  [12]: Kim, B., Rudin, C., &amp; Shah, J. A. (2014). The bayesian case model: A generative approach for case-based reasoning and prototype classification. Advances in neural information processing systems, 27, 1952-1960.</p>
<p>  [13]: Jeyakumar, J. V., Noor, J., Cheng, Y. H., Garcia, L., &amp; Srivastava, M. (2020). How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods. Advances in Neural Information Processing Systems, 33.</p>
<p>  [14]: Papernot, N., &amp; McDaniel, P. (2018). Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning. arXiv preprint arXiv:1803.04765.</p>
<p>  [15]: Ming, Y., Xu, P., Qu, H., &amp; Ren, L. (2019, July). Interpretable and steerable sequence learning via prototypes. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (pp. 903-913).</p>
<p>  [16]: Ma, D., Wang, Z., Xie, J., Guo, B., &amp; Yu, Z. (2020, November). Interpretable Multivariate Time Series Classification Based on Prototype Learning. In International Conference on Green, Pervasive, and Cloud Computing (pp. 205-216). Springer, Cham.</p>
<p>  [17]: Keane, M. T., &amp; Kenny, E. M. (2019, September). How case-based reasoning explains neural networks: A theoretical analysis of XAI using post-hoc explanation-by-example from a survey of ANN-CBR twin-systems. In International Conference on Case-Based Reasoning (pp. 155-171). Springer, Cham.</p>
<h2 id="经典论文or强相关论文"><a href="#经典论文or强相关论文" class="headerlink" title="经典论文or强相关论文"></a>经典论文or强相关论文</h2><p>  [11]: Nicolas Papernot and Patrick McDaniel. Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning. arXiv preprint arXiv:1803.04765, 2018.</p>
<p>  [13]: Jeyakumar, J. V., Noor, J., Cheng, Y. H., Garcia, L., &amp; Srivastava, M. (2020). How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods. Advances in Neural Information Processing Systems, 33.</p>
<p>  <strong>异同点</strong></p>
<p>  [11, 13]: 分析的是有监督分类模型中的基于案例的可解释问题，但仅能说明某样本为何被判定为某类，而不能做出反事实（counterfactual:）解释，即“某样本为何不是某类”。无法从中提取出可以用于分类的语义信息</p>
<p>  [11, 13]: 和我们的工作均从隐空间入手，分析待测样本的邻居，而我们进一步的分析了待测样本与其邻居、聚类中心样本 之间的差异，以帮助我们总结有助于区分正异常的语义信息。</p>
 
            </div>
        </div>
        
        <div class="mt-3">
            <!-- 前一页后一页 -->
<div class="previous-next-links">
     
    <div class="previous-design-link">
        <a href="../../paperlistfile/NDSS2020/">
            <i style="font-size:16px;" class="fa fa-arrow-left" aria-hidden="true"></i>
            Related Papers in NDSS 2020（安全领域的顶会）
        </a>
    </div>
     

     
    <div class="next-design-link">
        <a href="../interpretable_DNN/">
            Self-explaining DNN
            <i style="font-size:16px;" class="fa fa-arrow-right" aria-hidden="true"></i>
        </a>
    </div>
 
</div> 
             
        </div>

    </div>
    <div class="col-2">
        <div class="d-none d-sm-none d-md-block sticky-top border-start">
             
    
        <div>
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">研究问题描述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%86%E5%9F%9F%E7%8E%B0%E7%8A%B6"><span class="toc-number">2.</span> <span class="toc-text">领域现状</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%8F%A0%E5%8A%A0%E7%9A%84%E6%96%B9%E6%B3%95-Superimposition-based-explanation"><span class="toc-number">2.1.</span> <span class="toc-text">基于叠加的方法 (Superimposition-based explanation)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%BE%8B%E5%AD%90%E7%9A%84%E6%96%B9%E6%B3%95-example-based-explanation"><span class="toc-number">2.2.</span> <span class="toc-text">基于例子的方法 (example-based explanation)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E8%A1%A8%E6%80%A7%E8%AE%BA%E6%96%8710%E7%AF%87"><span class="toc-number">3.</span> <span class="toc-text">代表性论文10篇</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%8F%A0%E5%8A%A0%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.</span> <span class="toc-text">基于叠加的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%BE%8B%E5%AD%90%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">3.2.</span> <span class="toc-text">基于例子的方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87or%E5%BC%BA%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87"><span class="toc-number">4.</span> <span class="toc-text">经典论文or强相关论文</span></a></li></ol> 
        </div>
    
 

        </div>
    </div>
</div>
</div>
 
    </main>

    <!-- 底部栏 -->
    <footer class="bg-dark pt-1 pb-0 mt-5">
    <div class="container pb-3 pt-3 text-center">
        <p class="text-muted tag-hover">
            Powered by 
             <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://hexo.io">
                 Hexo.io
            </a> &  <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://github.com/smile-yan/hexo-theme-heyan">
               heyan
            </a>
            <br>
        </p>
    </div>
</footer>
</body> 
</html>