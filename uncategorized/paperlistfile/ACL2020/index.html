
<!DOCTYPE html>
<html>
<head>
    <title>Smileyan</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">
    <link href="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
    <script src="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
    
<link rel="stylesheet" href="../../../css/prism.css">
 
    
<script src="../../../js/prism.js"></script>

    
    
<link rel="stylesheet" href="../../../css/index.css">
 
    
<script src="../../../js/search.js"></script>



     
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
        </script>
     

     
        <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"> </script>
        
<script src="../../../js/fancybox.js"></script>

    

    <script type="text/javascript">
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
        var path = "/" + search_path;
        searchFunc(path, 'local-search-input', 'local-search-result');
    </script>
<meta name="generator" content="Hexo 5.4.2"></head>
 
 
<body>
    <!-- 导航栏 -->
    <!-- 导航栏 -->
<nav class="navbar navbar-expand-md navbar-dark bg-dark mb-4 pt-2 pb-2">
    <div class="container">
        <!-- 标题 --> 
        <a class="navbar-brand navbar-expand-sm" href="/">
            <img class="nofancybox" src="/logo.png" style="width: 75px;"  alt="笑颜网">
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <!-- 左边右边导航按钮 --> 
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto">
                <!-- 左右两侧的导航栏 -->

 
 

    <li class="nav-item">
        <a class="nav-link" href="../../../">
           <big> <i class="fa fa-home ps-1" ></i> 主页</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../archives">
           <big> <i class="fa fa-archive ps-1" ></i> 归档</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../about">
           <big> <i class="fa fa-user ps-1" ></i> 关于</big>
        </a>
    </li>
 
 
            </ul>

            
            <form class="">
                <div class="d-flex">
                    <button class="btn text-muted fa fa-search d-none d-md-block d-lg-block" disabled></button>
                    <input id="local-search-input" class="form-control me-2 pe-4" type="search"
                            placeholder="搜索 " aria-label="Search">
                </div>
                <div id="local-search-result" style="position:absolute; padding-top: 8px; max-height: 960px; width: 480px;overflow-y: scroll; z-index: 1050;"></div>
            </form>
            
            <ul class="navbar-nav">
                <!-- 左右两侧的导航栏 -->

 
 
            </ul>
        </div>
    </div>
</nav>


    <main class="container">
        
<div class="container-fluid markdown-section">
<div class="row">
    <div class="col-md-2 d-none d-sm-none d-md-block">
        <div class="">
            <!-- 同一类型的文件 -->
<!-- 尽可能做到每篇文章只有一个类
    1. 获得 post 的类别 categories
     2.1 如果 categories.length === 0，啥也不做
     2.2 如果 categories === 1，渲染这个类的所有文章
     2.3 如果 categories.length > 1 ，则以第一个类为准渲染所有文章
-->


 
        </div>
    </div>
    <div class="col-md-8 col-sm-12">
        <!-- 博客详情 -->
        <div class="">
            <!-- ps-4 pe-4 pt-2 -->
            <p class="h2">
                <span class="post-title">
                    Related Papers in ACL 2020 (2020.07.06)
                </span>   
            </p>

            <div class="pb-3 pt-1 pe-3">
                <i class="fa fa-calendar p-1"></i>
                2020/07/06 00:00:00 

                <i class="fa fa-calendar p-1"></i>
                2022/04/12 16:30:41 


                <i class="fa fa-folder-open p-1"> </i> 
                <span class="tag-hover">
                     
                </span>

                <i class="fa fa-tag p-1"> </i>
                <span class="tag-hover">
                    
                        <a href="../../../tags/paper-list/" class="link-dark text-decoration-none"> 
                            paper list 
                        </a>
                    
                </span>
            </div>

            <div class="border-bottom pb-2">
                <p><a target="_blank" rel="noopener" href="https://acl2020.org/program/accepted/">Link</a></p>
<span id="more"></span>

<h2 id="Recurrent-Neural-Network"><a href="#Recurrent-Neural-Network" class="headerlink" title="Recurrent Neural Network"></a>Recurrent Neural Network</h2><ul>
<li><p>Generating Informative Conversational Response using Recurrent Knowledge-Interaction and Knowledge-Copy</p>
<p>Xiexiong Lin, Weiyu Jian, Jianshan He, Taifeng Wang and Wei Chu</p>
</li>
<li><p>MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning</p>
<p>Jie Lei, Liwei Wang, Yelong Shen, Dong Yu, Tamara Berg and Mohit Bansal</p>
</li>
<li><p>Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension</p>
<p>Hongyu Gong, Yelong Shen, Dian Yu, Jianshu Chen and Dong Yu</p>
</li>
<li><p>Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment</p>
<p>Forrest Davis and Marten van Schijndel</p>
</li>
<li><p>Synchronous Double-channel Recurrent Network for Aspect-Opinion Pair Extraction</p>
<p>Shaowei Chen, Jie Liu, Yu Wang, Wenzheng Zhang and Ziming Chi</p>
</li>
</ul>
<h2 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h2><ul>
<li><p>Autoencoding Pixies: Amortised Variational Inference with Graph Convolutions for Functional Distributional Semantics</p>
<p>Guy Emerson</p>
</li>
<li><p>Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder</p>
<p>Daya Guo, Duyu Tang, Nan Duan, Jian Yin, Daxin Jiang and Ming Zhou</p>
</li>
<li><p>Semi-Supervised Semantic Dependency Parsing Using CRF Autoencoders</p>
<p>Zixia Jia, Youmi Ma, Jiong Cai and Kewei Tu</p>
</li>
<li><p>Autoencoding Keyword Correlation Graph for Document Clustering</p>
<p>Billy Chiu, Sunil Kumar Sahu, Derek Thomas, Neha Sengupta and Mohammady Mahdy</p>
</li>
<li><p>Crossing Variational Autoencoders for Answer Retrieval</p>
<p>Wenhao Yu, Lingfei Wu, Qingkai Zeng, Shu Tao, Yu Deng and Meng Jiang</p>
</li>
<li><p>Interpretable Operational Risk Classification with Semi-Supervised Variational Autoencoder</p>
<p>Fan Zhou, Shengming Zhang and Yi Yang</p>
</li>
<li><p>SCAR: Sentence Compression using Autoencoders for Reconstruction</p>
<p>Chanakya Malireddy, Tirth Maniar and Manish Shrivastava</p>
</li>
</ul>
<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><ul>
<li><p>Inducing Grammar from Long Short-Term Memory Networks by Shapley Decomposition</p>
<p>Yuhui Zhang and Allen Nie</p>
</li>
</ul>
<h2 id="Sequence"><a href="#Sequence" class="headerlink" title="Sequence"></a>Sequence</h2><ul>
<li><p>A Study of Non-autoregressive Model for Sequence Generation</p>
<p>Yi Ren, Jinglin Liu, Xu Tan, Zhou Zhao, Sheng Zhao and Tie-Yan Liu</p>
</li>
<li><p><strong>已读</strong> BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</p>
<p>Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov and Luke Zettlemoyer</p>
</li>
<li><p>Conditional Augmentation for Aspect Term Extraction via Masked Sequence-to-Sequence Generation</p>
<p>Kun Li, Chengbo Chen, Xiaojun Quan, Qing Ling and Yan Song</p>
</li>
<li><p>DeSePtion: Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking</p>
<p>Christopher Hidey, Tuhin Chakrabarty, Tariq Alhindi, Siddharth Varia, Kriste Krstovski, Mona Diab and Smaranda Muresan</p>
</li>
<li><p>Estimating the influence of auxiliary tasks for multi-task learning of sequence tagging tasks</p>
<p>Fynn Schröder and Chris Biemann</p>
</li>
<li><p>Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation</p>
<p>Junliang Guo, Linli Xu and Enhong Chen</p>
</li>
<li><p>Location Attention for Extrapolation to Longer Sequences</p>
<p>Yann Dubois, Gautier Dagan, Dieuwke Hupkes and Elia Bruni</p>
</li>
<li><p>NAT: Noise-Aware Training for Robust Neural Sequence Labeling</p>
<p>Marcin Namysl, Sven Behnke and Joachim Köhler</p>
</li>
<li><p>SeqVAT: Virtual Adversarial Training for Semi-Supervised Sequence Labeling</p>
<p>Luoxin Chen, Weitong Ruan, Xinyue Liu and Jianhua Lu</p>
</li>
<li><p>Structure-Level Knowledge Distillation For Multilingual Sequence Labeling</p>
<p>Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Fei Huang and Kewei Tu</p>
</li>
<li><p>Enriched In-Order Linearization for Faster Sequence-to-Sequence Constituent Parsing</p>
<p>Daniel Fernández-González and Carlos Gómez-Rodríguez</p>
</li>
<li><p>Low Resource Sequence Tagging using Sentence Reconstruction</p>
<p>Tal Perl, Sriram Chaudhury and Raja Giryes</p>
</li>
<li><p>Embeddings of Label Components for Sequence Labeling: A Case Study of Fine-grained Named Entity Recognition</p>
<p>Takuma Kato, Kaori Abe, Hiroki Ouchi, Shumpei Miyawaki, Jun Suzuki and Kentaro Inui</p>
</li>
</ul>
<h2 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h2><ul>
<li><p>AdvAug: Robust Adversarial Augmentation for Neural Machine Translation</p>
<p>Yong Cheng, Lu Jiang, Wolfgang Macherey and Jacob Eisenstein</p>
</li>
<li><p>Conditional Augmentation for Aspect Term Extraction via Masked Sequence-to-Sequence Generation</p>
<p>Kun Li, Chengbo Chen, Xiaojun Quan, Qing Ling and Yan Song</p>
</li>
<li><p>Good-Enough Compositional Data Augmentation</p>
<p>Jacob Andreas</p>
<p>由于语言任务中的某些模式具有通用性，为了让神经网络学习到这些通用性，从而提出这种增强方法，具体方法：</p>
</li>
</ul>
<ol>
<li>分析数据集中的语言模式，即在同样的语言环境中出现的不同词句，这些不同字句就是需要被学习到的通用性，下面是一对例子。<ol>
<li><strong>She</strong> <em>picks</em> <strong>the wug</strong> <em>up</em> <strong>in</strong> Fresno.</li>
<li><strong>She</strong> <em>puts</em> <strong>the wug</strong> <em>down</em> <strong>in</strong> Tempe.</li>
</ol>
</li>
<li>在这个例子中，粗体部分代表着同样的语言环境，则斜体部分则为需要学习到的通用性，在网络受到1的句子的时候，也需要具备推导出2中斜体部分内容的能力。</li>
</ol>
<ul>
<li><p>Review-based Question Generation with Adaptive Instance Transfer and Augmentation</p>
<p>Qian Yu, Lidong Bing, Qiong Zhang, Wai Lam and Luo Si</p>
</li>
<li><p>Logic-Guided Data Augmentation and Regularization for Consistent Question Answering</p>
<p>Akari Asai and Hannaneh Hajishirzi</p>
</li>
<li><p>Parallel Data Augmentation for Formality Style Transfer</p>
<p>Yi Zhang, Tao Ge and Xu SUN</p>
</li>
<li><p>Syntactic Data Augmentation Increases Robustness to Inference Heuristics</p>
<p>Junghyun Min, R. Thomas McCoy, Dipanjan Das, Emily Pitler and Tal Linzen</p>
</li>
<li><p>Noise-Based Augmentation Techniques for Emotion Datasets: What do we Recommend?</p>
<p>Mimansa Jaiswal and Emily Mower Provost</p>
</li>
</ul>
 
            </div>
        </div>
        
        <div class="mt-3">
            <!-- 前一页后一页 -->
<div class="previous-next-links">
     
    <div class="previous-design-link">
        <a href="../ICML2020/">
            <i style="font-size:16px;" class="fa fa-arrow-left" aria-hidden="true"></i>
            Related Papers in ICML 2020 (2020.07.12)
        </a>
    </div>
     

     
    <div class="next-design-link">
        <a href="../../surveys/extra-large_dataset/">
            超大规模数据集（TB级别以上）调研
            <i style="font-size:16px;" class="fa fa-arrow-right" aria-hidden="true"></i>
        </a>
    </div>
 
</div> 
             
        </div>

    </div>
    <div class="col-2">
        <div class="d-none d-sm-none d-md-block sticky-top border-start">
             
    
        <div>
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Recurrent-Neural-Network"><span class="toc-number">1.</span> <span class="toc-text">Recurrent Neural Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Autoencoder"><span class="toc-number">2.</span> <span class="toc-text">Autoencoder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LSTM"><span class="toc-number">3.</span> <span class="toc-text">LSTM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sequence"><span class="toc-number">4.</span> <span class="toc-text">Sequence</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-augmentation"><span class="toc-number">5.</span> <span class="toc-text">Data augmentation</span></a></li></ol> 
        </div>
    
 

        </div>
    </div>
</div>
</div>
 
    </main>

    <!-- 底部栏 -->
    <footer class="bg-dark pt-1 pb-0 mt-5">
    <div class="container pb-3 pt-3 text-center">
        <p class="text-muted tag-hover">
            All Rights Reserved <i class="fa fa-copyright"></i> 2017-2022 笑颜网 smileyan.cn <br> 
            Powered by 
             <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://hexo.io">
                 Hexo.io
            </a> &  <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://github.com/smile-yan/hexo-theme-heyan">
               heyan
            </a>
            <br>
            <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/#/Integrated/index">
                <img src="/police.png" style="width: 18px; height: 18px; margin-top: -4px" class="nofancybox">
                湘ICP备 17012851号 
            </a>
        </p>
    </div>
</footer>
</body> 
</html>