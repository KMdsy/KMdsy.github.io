
<!DOCTYPE html>
<html>
<head>
    <title>Smileyan</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">
    <link href="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
    <script src="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
    
<link rel="stylesheet" href="../../../css/prism.css">
 
    
<script src="../../../js/prism.js"></script>

    
    
<link rel="stylesheet" href="../../../css/index.css">
 
    
<script src="../../../js/search.js"></script>



     
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
        </script>
     

     
        <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"> </script>
        
<script src="../../../js/fancybox.js"></script>

    

    <script type="text/javascript">
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
        var path = "/" + search_path;
        searchFunc(path, 'local-search-input', 'local-search-result');
    </script>
<meta name="generator" content="Hexo 5.4.2"></head>
 
 
<body>
    <!-- 导航栏 -->
    <!-- 导航栏 -->
<nav class="navbar navbar-expand-md navbar-dark bg-dark mb-4 pt-2 pb-2">
    <div class="container">
        <!-- 标题 --> 
        <a class="navbar-brand navbar-expand-sm" href="/">
            <img class="nofancybox" src="/logo.png" style="width: 75px;"  alt="笑颜网">
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <!-- 左边右边导航按钮 --> 
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto">
                <!-- 左右两侧的导航栏 -->

 
 

    <li class="nav-item">
        <a class="nav-link" href="../../../">
           <big> <i class="fa fa-home ps-1" ></i> 主页</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../archives">
           <big> <i class="fa fa-archive ps-1" ></i> 归档</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../about">
           <big> <i class="fa fa-user ps-1" ></i> 关于</big>
        </a>
    </li>
 
 
            </ul>

            
            <form class="">
                <div class="d-flex">
                    <button class="btn text-muted fa fa-search d-none d-md-block d-lg-block" disabled></button>
                    <input id="local-search-input" class="form-control me-2 pe-4" type="search"
                            placeholder="搜索 " aria-label="Search">
                </div>
                <div id="local-search-result" style="position:absolute; padding-top: 8px; max-height: 960px; width: 480px;overflow-y: scroll; z-index: 1050;"></div>
            </form>
            
            <ul class="navbar-nav">
                <!-- 左右两侧的导航栏 -->

 
 
            </ul>
        </div>
    </div>
</nav>


    <main class="container">
        
<div class="container-fluid markdown-section">
<div class="row">
    <div class="col-md-2 d-none d-sm-none d-md-block">
        <div class="">
            <!-- 同一类型的文件 -->
<!-- 尽可能做到每篇文章只有一个类
    1. 获得 post 的类别 categories
     2.1 如果 categories.length === 0，啥也不做
     2.2 如果 categories === 1，渲染这个类的所有文章
     2.3 如果 categories.length > 1 ，则以第一个类为准渲染所有文章
-->


 
        </div>
    </div>
    <div class="col-md-8 col-sm-12">
        <!-- 博客详情 -->
        <div class="">
            <!-- ps-4 pe-4 pt-2 -->
            <p class="h2">
                <span class="post-title">
                    Related Papers in ICLR 2020 (2020.04.26)
                </span>   
            </p>

            <div class="pb-3 pt-1 pe-3">
                <i class="fa fa-calendar p-1"></i>
                2020/04/26 00:00:00 

                <i class="fa fa-pencil"> </i>
                2022/04/12 16:30:46 

                <!--
                <i class="fa fa-folder-open p-1"> </i> 
                <span class="tag-hover">
                     
                </span>
                -->

                <i class="fa fa-tags p-1"> </i>
                <span class="tag-hover">
                    
                        <a href="../../../tags/paper-list/" class="link-dark text-decoration-none"> 
                            paper list 
                        </a>
                    
                </span>
            </div>

            <div class="border-bottom pb-2">
                <p><a target="_blank" rel="noopener" href="https://openreview.net/group?id=ICLR.cc/2020/Conference">Link</a></p>
<span id="more"></span>

<h2 id="Anomaly"><a href="#Anomaly" class="headerlink" title="Anomaly"></a>Anomaly</h2><ul>
<li><p><strong>已读</strong> Deep Semi-Supervised Anomaly Detection </p>
<p>Lukas Ruff, Robert A. Vandermeulen, Nico Görnitz, Alexander Binder, Emmanuel Müller, Klaus-Robert Müller, Marius Kloft</p>
</li>
<li><p><strong>已读</strong>Iterative energy-based projection on a normal data manifold for anomaly localization </p>
<p>David Dehaene, Oriel Frigo, Sébastien Combrexelle, Pierre Eline</p>
<p><strong>任务</strong>：文章中说是异常定位，其实也可以看做异常归因，且针对以VAE/AE为基本结构的异常检测器均有效（个人理解对使用ONE CLASS方法训练、借助重建误差计算异常得分的方法均有效）。</p>
<p><strong>基本流程</strong>：</p>
<ol>
<li><p>本文假设使用一个VAE结构做ONE CLASS训练，即建模正常数据的重建与分布。Loss函数为: $L = L_{reconstruction} + L_{KL(p,q)}$</p>
</li>
<li><p>由于上述的loss函数最小化了网络对于正常样本的相应。因此，针对任意一个异常样本$x_a$，将网络对其的相应$L(x)$做最小化，即可将$x_a$转换它的正常版本$x_n$。在这种假设下，网络的loss函数即为样本的异常得分。</p>
</li>
<li><p>定义异常定位的最优化目标$E = L$，由于有工作表明$L_{KL}$对计算异常得分有负面作用，因此将loss函数中的此项去掉。即$E = L_{reconstruction}$。</p>
</li>
<li><p>由于定位的目标是仅使得样本中异常的部分被指出。而非改变整个样本的形态到类似训练样本的样子，所以要加上正则项，控制正常版本的样本与原异常样本之间的相似度，即 $L_{regularization} = \left| x_n - x_a \right| <em>0 $，然而由于L0不可导，因此使用L1作为近似，即$L</em>{regularization} = \left| x_n - x_a \right|<em>1 $。即用于定位异常的优化目标energy为$E = L</em>{reconstruction} + \left| x_n - x_a \right|<em>1 $，上式中的$x_n$等同于下面表述的$x</em>{old}$。</p>
</li>
<li><p>如何迭代式的将$x_a$转为$x_n$？定义梯度下降操作$x_{new} = x_{old} - \alpha * \nabla _x (E)$</p>
</li>
<li><p>由于仅需要对异常的像素进行更新，所以在上述公式上加一层Mask，即$x_{new} = x_{old} - \alpha * (\nabla <em>x (E) \odot Mask)$，但是在无监督的情况下，$Mask$是未知的，因此使用像素级的重建误差来代替。则样本更新公式为$x</em>{new} = x_{old} - \alpha * (\nabla <em>x (E) \odot (x</em>{old} - f_{VAE}(x_{old}))^2)$</p>
</li>
</ol>
<blockquote>
<p>Optimizing the energy this way, a pixel where the reconstruction error is high will update faster, whereas a pixel with good reconstruction<br>will not change easily. This prevents the image to update its pixels where the reconstruction is already good, even with a high learning rate.</p>
</blockquote>
</li>
<li><p><strong>已读</strong> Robust anomaly detection and backdoor attack detection via differential privacy </p>
<p>Min Du, Ruoxi Jia, Dawn Song</p>
</li>
<li><p>Classification-Based Anomaly Detection for General Data <em>General Data: 多种数据类型，图像、xxx等等</em></p>
<p>Liron Bergman, Yedid Hoshen </p>
</li>
<li><p><strong>已读</strong> Robust Subspace Recovery Layer for Unsupervised Anomaly Detection</p>
<p>Chieh-Hsin Lai, Dongmian Zou, Gilad Lerman</p>
</li>
<li><p>Attention Guided Anomaly Detection and Localization in ImagesArXiv2019</p>
<p>Shashanka VenkataramananKuan-Chuan PengRajat Vikram SinghAbhijit Mahalanobis</p>
</li>
</ul>
<h2 id="Sequence"><a href="#Sequence" class="headerlink" title="Sequence"></a>Sequence</h2><ul>
<li><p>Are Transformers universal approximators of sequence-to-sequence functions? </p>
<p>Chulhee Yun, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank Reddi, Sanjiv Kumar</p>
</li>
<li><p>DeFINE: Deep Factorized Input Token Embeddings for Neural Sequence Modeling </p>
</li>
<li><p>Revisiting Self-Training for Neural Sequence Generation </p>
<p>Junxian He, Jiatao Gu, Jiajun Shen, Marc’Aurelio Ranzato</p>
</li>
<li><p>Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation </p>
<p>Xinjie Fan, Yizhe Zhang, Zhendong Wang, Mingyuan Zhou</p>
</li>
<li><p>Compressive Transformers for Long-Range Sequence Modelling </p>
<p>Jack W. Rae, Anna Potapenko, Siddhant M. Jayakumar, Chloe Hillier, Timothy P. Lillicrap</p>
</li>
<li><p>Model-based reinforcement learning for biological sequence design </p>
<p>Christof Angermueller, David Dohan, David Belanger, Ramya Deshpande, Kevin Murphy, Lucy Colwell</p>
</li>
<li><p>Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models </p>
<p>Xisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, Xiang Ren</p>
</li>
</ul>
<h2 id="Time-Series"><a href="#Time-Series" class="headerlink" title="Time Series"></a>Time Series</h2><ul>
<li><p><strong>已读</strong> N-BEATS: Neural basis expansion analysis for interpretable time series forecasting <em>可解释性上的工作</em></p>
<p>Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio</p>
</li>
<li><p>Dynamic Time Lag Regression: Predicting What &amp; When </p>
<p>Mandar Chandorkar, Cyril Furtlehner, Bala Poduval, Enrico Camporeale, Michele Sebag</p>
</li>
<li><p>Intensity-Free Learning of Temporal Point Processes </p>
<p>Oleksandr Shchur, Marin Biloš, Stephan Günnemann</p>
</li>
</ul>
<h2 id="Recurrent"><a href="#Recurrent" class="headerlink" title="Recurrent"></a>Recurrent</h2><ul>
<li><p>Variational Recurrent Models for Solving Partially Observable Control Tasks </p>
<p>Dongqi Han, Kenji Doya, Jun Tani</p>
</li>
<li><p>One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum Evaluation </p>
<p>Shunshi Zhang, Bradly C. Stadie</p>
</li>
<li><p>Recurrent neural circuits for contour detection </p>
<p>Drew Linsley*, Junkyung Kim*, Alekh Ashok, Thomas Serre</p>
</li>
<li><p>Improved memory in recurrent neural networks with sequential non-normal dynamics <em>是否可以使用non-normal来描述我们的工作中的系统</em></p>
<p>Emin Orhan, Xaq Pitkow</p>
</li>
<li><p>Economy Statistical Recurrent Units For Inferring Nonlinear Granger Causality </p>
<p>Saurabh Khanna, Vincent Y. F. Tan</p>
</li>
<li><p>Decoding As Dynamic Programming For Recurrent Autoregressive Models </p>
<p>Najam Zaidi, Trevor Cohn, Gholamreza Haffari</p>
</li>
<li><p>Training Recurrent Neural Networks Online by Learning Explicit State Variables </p>
<p>Somjit Nath, Vincent Liu, Alan Chan, Xin Li, Adam White, Martha White</p>
</li>
<li><p>Understanding Generalization in Recurrent Neural Networks </p>
<p>Zhuozhuo Tu, Fengxiang He, Dacheng Tao</p>
</li>
<li><p>RNNs Incrementally Evolving on an Equilibrium Manifold: A Panacea for Vanishing and Exploding Gradients? </p>
<p>Anil Kag, Ziming Zhang, Venkatesh Saligrama </p>
</li>
<li><p>Implementing Inductive bias for different navigation tasks through diverse RNN attrractors </p>
<p>Tie XU, Omri Barak</p>
</li>
<li><p>Symplectic Recurrent Neural Networks </p>
<p>Zhengdao Chen, Jianyu Zhang, Martin Arjovsky, Léon Bottou</p>
</li>
</ul>
<h2 id="Interpretable"><a href="#Interpretable" class="headerlink" title="Interpretable"></a>Interpretable</h2><ul>
<li><p>Overlearning Reveals Sensitive Attributes </p>
<p>Congzheng Song, Vitaly Shmatikov</p>
</li>
<li><p>Explain Your Move: Understanding Agent Actions Using Specific and Relevant Feature Attribution </p>
<p>Nikaash Puri, Sukriti Verma, Piyush Gupta, Dhruv Kayastha, Shripad Deshmukh, Balaji Krishnamurthy, Sameer Singh</p>
</li>
</ul>
<h2 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h2><ul>
<li><p><strong>已读</strong> From Variational to Deterministic Autoencoders</p>
<p>Partha Ghosh, Mehdi S. M. Sajjadi, Antonio Vergari, Michael Black, Bernhard Scholkopf</p>
</li>
<li><p>MIXED-CURVATURE VARIATIONAL AUTOENCODERS</p>
</li>
<li><p>Mogrifier LSTM </p>
<p>Gábor Melis, Tomáš Kočiský, Phil Blunsom</p>
</li>
</ul>
<h2 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h2><ul>
<li><p>ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring </p>
<p>David Berthelot, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, Colin Raffel</p>
</li>
</ul>
 
            </div>
        </div>
        
        <div class="mt-3">
            <!-- 前一页后一页 -->
<div class="previous-next-links">
     
    <div class="previous-design-link">
        <a href="../../surveys/cov19_papers/">
            <i style="font-size:16px;" class="fa fa-arrow-left" aria-hidden="true"></i>
            调研：美国COVID19感染/死亡、历史流感感染/死亡
        </a>
    </div>
     

     
    <div class="next-design-link">
        <a href="../../surveys/timesimilar/">
            Time series similarity learning
            <i style="font-size:16px;" class="fa fa-arrow-right" aria-hidden="true"></i>
        </a>
    </div>
 
</div> 
             
        </div>

    </div>
    <div class="col-2">
        <div class="d-none d-sm-none d-md-block sticky-top border-start">
             
    
        <div>
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Anomaly"><span class="toc-number">1.</span> <span class="toc-text">Anomaly</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sequence"><span class="toc-number">2.</span> <span class="toc-text">Sequence</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Time-Series"><span class="toc-number">3.</span> <span class="toc-text">Time Series</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recurrent"><span class="toc-number">4.</span> <span class="toc-text">Recurrent</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Interpretable"><span class="toc-number">5.</span> <span class="toc-text">Interpretable</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Autoencoder"><span class="toc-number">6.</span> <span class="toc-text">Autoencoder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-augmentation"><span class="toc-number">7.</span> <span class="toc-text">Data augmentation</span></a></li></ol> 
        </div>
    
 

        </div>
    </div>
</div>
</div>
 
    </main>

    <!-- 底部栏 -->
    <footer class="bg-dark pt-1 pb-0 mt-5">
    <div class="container pb-3 pt-3 text-center">
        <p class="text-muted tag-hover">
            All Rights Reserved <i class="fa fa-copyright"></i> 2017-2022 笑颜网 smileyan.cn <br> 
            Powered by 
             <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://hexo.io">
                 Hexo.io
            </a> &  <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://github.com/smile-yan/hexo-theme-heyan">
               heyan
            </a>
            <br>
            <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/#/Integrated/index">
                <img src="/police.png" style="width: 18px; height: 18px; margin-top: -4px" class="nofancybox">
                湘ICP备 17012851号 
            </a>
        </p>
    </div>
</footer>
</body> 
</html>