
<!DOCTYPE html>
<html>
<head>
    <title> Here is Shaoyu </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--网页标题左侧显示-->
    <link rel="icon" href="/fish.ico" type="image/x-icon">
    <!--收藏夹显示图标-->
    <link rel="shortcut icon" href="/fish.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">
    <link href="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
    <script src="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
    
<link rel="stylesheet" href="../../../css/prism.css">
 
    
<script src="../../../js/prism.js"></script>

    
    
<link rel="stylesheet" href="../../../css/index.css">
 
    
<script src="../../../js/search.js"></script>



     
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
        </script>
     

     
        <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"> </script>
        
<script src="../../../js/fancybox.js"></script>

    

    <script type="text/javascript">
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
        var path = "/" + search_path;
        searchFunc(path, 'local-search-input', 'local-search-result');
    </script>
<meta name="generator" content="Hexo 5.4.2"></head>
 
 
<body>
    <!-- 导航栏 -->
    <!-- 导航栏 -->
<nav class="navbar navbar-expand-md navbar-dark bg-dark mb-4 pt-2 pb-2">
    <div class="container">
        <!-- 标题 --> 
        <a class="navbar-brand navbar-expand-sm" href="/">
            <img class="nofancybox" src="/shark.svg" style="width: 65px;">
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <!-- 左边右边导航按钮 --> 
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto">
                <!-- 左右两侧的导航栏 -->

 
 

    <li class="nav-item">
        <a class="nav-link" href="../../../">
           <big> <i class="fa fa-home ps-1" ></i> Home</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../note">
           <big> <i class="fa fa-file-text-o ps-1" ></i> Notes</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../survey">
           <big> <i class="fa fa-globe ps-1" ></i> Surveys</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../paperlist">
           <big> <i class="fa fa-cc-discover ps-1" ></i> Paper Lists</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../archives">
           <big> <i class="fa fa-archive ps-1" ></i> Archives</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../about">
           <big> <i class="fa fa-user ps-1" ></i> About</big>
        </a>
    </li>
 
 
            </ul>

            
            <form class="">
                <div class="d-flex">
                    <button class="btn text-muted fa fa-search d-none d-md-block d-lg-block" disabled></button>
                    <input id="local-search-input" class="form-control me-2 pe-4" type="search"
                            placeholder="搜索 " aria-label="Search">
                </div>
                <div id="local-search-result" style="position:absolute; padding-top: 8px; max-height: 960px; width: 480px;overflow-y: scroll; z-index: 1050;"></div>
            </form>
            
            <ul class="navbar-nav">
                <!-- 左右两侧的导航栏 -->

 
 
            </ul>
        </div>
    </div>
</nav>


    <main class="container">
        
<div class="container-fluid markdown-section">
<div class="row">
    <div class="col-md-2 d-none d-sm-none d-md-block">
        <div class="">
            <!-- 同一类型的文件 -->
<!-- 尽可能做到每篇文章只有一个类
    1. 获得 post 的类别 categories
     2.1 如果 categories.length === 0，啥也不做
     2.2 如果 categories === 1，渲染这个类的所有文章
     2.3 如果 categories.length > 1 ，则以第一个类为准渲染所有文章
-->


 
        </div>
    </div>
    <div class="col-md-8 col-sm-12">
        <!-- 博客详情 -->
        <div class="">
            <!-- ps-4 pe-4 pt-2 -->
            <p class="h2">
                <span class="post-title">
                    Related Papers in ICLR 2022 (2022.04.25)
                </span>   
            </p>

            <div class="pb-3 pt-1 pe-3">
                <i class="fa fa-calendar p-1"></i>
                2022/02/25 00:00:00 

                <i class="fa fa-pencil"> </i>
                2022/02/25 00:00:00 

                <!--
                <i class="fa fa-folder-open p-1"> </i> 
                <span class="tag-hover">
                     
                </span>
                -->

                <i class="fa fa-tags p-1"> </i>
                <span class="tag-hover">
                    
                        <a href="../../../tags/paper-list/" class="link-dark text-decoration-none"> 
                            paper list 
                        </a>
                    
                </span>
            </div>

            <div class="border-bottom pb-2">
                <p><a target="_blank" rel="noopener" href="https://openreview.net/group?id=ICLR.cc/2022/Conference">Accept paper list</a></p>
<span id="more"></span>

<h2 id="anomaly-detection-anomaly-outlier-out-of-distribution-one-class"><a href="#anomaly-detection-anomaly-outlier-out-of-distribution-one-class" class="headerlink" title="anomaly detection [anomaly, outlier, out-of-distribution, one-class]"></a>anomaly detection [anomaly, outlier, out-of-distribution, one-class]</h2><ul>
<li><p>Anomaly Detection for Tabular Data with Internal Contrastive Learning</p>
<p>Tom Shenkar, Lior Wolf</p>
<p><strong>摘要</strong>： 我们考虑在表格数据中寻找类外样本的任务，其中几乎不能假设数据的结构。<br>为了捕捉单个训练类样本的结构，我们学习了最大化每个样本与被屏蔽部分之间的互信息的映射。通过使用对比损失来学习映射，该损失一次只考虑一个样本。一旦学习，我们可以通过使用该样本的掩码部分测量学习的映射是否导致小的对比损失来对测试样本进行评分。我们的实验表明，与文献相比，我们的方法存在相当大的准确性差距，并且相同的默认超参数集在基准测试中提供了最先进的结果。</p>
<p><strong>一句话总结</strong>： 一种基于预测向量中被屏蔽部分的能力的异常检测方法。</p>
</li>
<li><p>Igeood: An Information Geometry Approach to Out-of-Distribution Detection </p>
<p>Eduardo Dadalto Camara Gomes, Florence Alberge, Pierre Duhamel, Pablo Piantanida</p>
<p><strong>摘要</strong>：可靠的分布外 (OOD) 检测是实现更安全的现代机器学习 (ML) 系统的基础。在本文中，我们介绍了 Igeood，一种检测 OOD 样本的有效方法。Igeood 适用于任何预训练的神经网络，在对 ML 模型的不同程度的访问下工作，不需要 OOD 样本或对 OOD 数据的假设，但也可以从 OOD 样本中受益（如果有的话）。通过建立基础数据分布之间的测地线（Fisher-Rao）距离，我们的鉴别器可以结合来自 logits 输出的置信度分数和深度神经网络的学习特征。根据经验，我们表明 Igeood 在各种网络架构和数据集上优于竞争的最先进方法。</p>
<p><strong>一句话总结</strong>： 我们通过建立概率分布之间的 Fisher-Rao 距离，提出了一种灵活有效的分布外检测方法。</p>
</li>
</ul>
<ul>
<li><p>VOS: Learning What You Don’t Know by Virtual Outlier Synthesis </p>
<p>Xuefeng Du, Zhaoning Wang, Mu Cai, Yixuan Li</p>
<p><strong>摘要</strong>： 由于其在神经网络的安全部署中的重要性，分布外（OOD）检测最近受到了很多关注。主要挑战之一是模型缺乏来自未知数据的监督信号，因此可能会对 OOD 数据产生过度自信的预测。以前的方法依赖于真正的异常数据集来进行模型正则化，这在实践中可能代价高昂，有时甚至不可行。在本文中，我们提出了 VOS，这是一种新的 OOD 检测框架，通过自适应合成虚拟异常值，可以在训练期间有意义地规范模型的决策边界。具体来说，VOS 从特征空间中估计的类条件分布的低似然区域采样虚拟异常值。此外，我们引入了一个新颖的未知感知训练目标，它对比地塑造了 ID 数据和合成异常值数据之间的不确定性空间。VOS 在物体检测和图像分类模型上都取得了具有竞争力的性能，与之前在物体检测器上的最佳方法相比，FPR95 降低了高达 7.87%。代码可在 <a target="_blank" rel="noopener" href="https://github.com/deeplearning-wisc/vos">https://github.com/deeplearning-wisc/vos</a> 获得。</p>
</li>
</ul>
<h2 id="Time-series"><a href="#Time-series" class="headerlink" title="Time series"></a>Time series</h2><ul>
<li><p>Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting </p>
<p>Shizhan Liu, Hang Yu, Cong Liao, Jianguo Li, Weiyao Lin, Alex X. Liu, Schahram Dustdar</p>
</li>
<li><p>CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting </p>
<p>Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, Steven Hoi</p>
</li>
<li><p>Huber Additive Models for Non-stationary Time Series Analysis </p>
<p>Yingjie Wang, Xianrui Zhong, Fengxiang He, Hong Chen, Dacheng Tao</p>
</li>
<li><p>DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting </p>
<p>Wei Fan, Shun Zheng, Xiaohan Yi, Wei Cao, Yanjie Fu, Jiang Bian, Tie-Yan Liu</p>
</li>
<li><p>Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift </p>
<p>Taesung Kim, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jang-Ho Choi, Jaegul Choo</p>
</li>
<li><p>Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification </p>
<p>Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Michael Blumenstein, Jing Jiang</p>
</li>
<li><p>T-WaveNet: A Tree-Structured Wavelet Neural Network for Time Series Signal Analysis </p>
<p>Minhao LIU, Ailing Zeng, Qiuxia LAI, Ruiyuan Gao, Min Li, Jing Qin, Qiang Xu</p>
</li>
<li><p>Graph-Guided Network for Irregularly Sampled Multivariate Time Series </p>
<p>Xiang Zhang, Marko Zeman, Theodoros Tsiligkaridis, Marinka Zitnik</p>
</li>
<li><p>Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled Time Series </p>
<p>Satya Narayan Shukla, Benjamin Marlin</p>
</li>
<li><p>Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks </p>
<p>Andrea Cini, Ivan Marisca, Cesare Alippi</p>
</li>
</ul>
<ul>
<li><p>Coherence-based Label Propagation over Time Series for Accelerated Active Learning </p>
<p>Yooju Shin, Susik Yoon, Sundong Kim, Hwanjun Song, Jae-Gil Lee, Byung Suk Lee</p>
</li>
<li><p>PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series </p>
<p>Paul Jeha, Michael Bohlke-Schneider, Pedro Mercado, Shubham Kapoor, Rajbir Singh Nirwan, Valentin Flunkert, Jan Gasthaus, Tim Januschowski</p>
</li>
</ul>
<h2 id="Sequence-learning"><a href="#Sequence-learning" class="headerlink" title="Sequence learning"></a>Sequence learning</h2><ul>
<li><p>Efficiently Modeling Long Sequences with Structured State Spaces </p>
<p>Albert Gu, Karan Goel, Christopher Re</p>
</li>
<li><p>Long Expressive Memory for Sequence Modeling </p>
<p>T. Konstantin Rusch, Siddhartha Mishra, N. Benjamin Erichson, Michael W. Mahoney</p>
</li>
<li><p><strong>【需要看看】</strong> On the approximation properties of recurrent encoder-decoder architectures<br>Zhong Li, Haotian Jiang, Qianxiao Li</p>
<p><strong>摘要</strong>： 编码器-解码器架构最近在序列到序列建模方面获得了普及，在最先进的模型（如转换器）中具有特色。然而，对其工作原理的数学理解仍然有限。在本文中，我们研究了循环编码器-解码器架构的近似特性。先前的工作为线性设置中的 RNN 建立了理论结果，其中近似能力可能与目标时间关系的平滑度和记忆有关。在这里，我们发现编码器和解码器一起形成了一个特定的“时间积结构”，它决定了逼近效率。此外，编码器-解码器架构泛化了具有学习时间非均匀关系的能力的 RNN。</p>
<p><strong>一句话总结</strong>： 给出了循环编码器-解码器架构的近似属性，其中形成的时间积结构进一步表征了能够有效学习<br>的时间关系。</p>
</li>
<li><p>Temporal Alignment Prediction for Supervised Representation Learning and Few-Shot Sequence Classification </p>
<p>Bing Su, Ji-Rong Wen</p>
</li>
</ul>
<h1 id="interpretable-interpretability"><a href="#interpretable-interpretability" class="headerlink" title="interpretable/interpretability"></a>interpretable/interpretability</h1><ul>
<li><p>Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset </p>
<p>Leon Sixt, Martin Schuessler, Oana-Iuliana Popescu, Philipp Weiß, Tim Landgraf</p>
</li>
<li><p>Toward Faithful Case-based Reasoning through Learning Prototypes in a Nearest Neighbor-friendly Space. </p>
<p>Seyed Omid Davoudi, Majid Komeili</p>
</li>
<li><p>Explaining Point Processes by Learning Interpretable Temporal Logic Rules </p>
<p>Shuang Li, Mingquan Feng, Lu Wang, Abdelmajid Essofi, Yufeng Cao, Junchi Yan, Le Song</p>
</li>
<li><p>Hidden Convexity of Wasserstein GANs: Interpretable Generative Models with Closed-Form Solutions </p>
<p>Arda Sahiner, Tolga Ergen, Batu Ozturkler, Burak Bartan, John M. Pauly, Morteza Mardani, Mert Pilanci</p>
</li>
<li><p>Model Agnostic Interpretability for Multiple Instance Learning </p>
<p>Joseph Early, Christine Evers, SArvapali Ramchurn</p>
</li>
<li><p>POETREE: Interpretable Policy Learning with Adaptive Decision Trees </p>
<p>Alizée Pace, Alex Chan, Mihaela van der Schaar</p>
</li>
<li><p>NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning </p>
<p>Chun-Hao Chang, Rich Caruana, Anna Goldenberg</p>
</li>
</ul>
 
            </div>
        </div>
        
        <div class="mt-3">
            <!-- 前一页后一页 -->
<div class="previous-next-links">
     
    <div class="previous-design-link">
        <a href="../Hotpaper%20in%202021-2022%20(Root%20Cause,%20Correlation)/">
            <i style="font-size:16px;" class="fa fa-arrow-left" aria-hidden="true"></i>
            Hotpaper in 2021-2022 (Root Cause, Correlation)
        </a>
    </div>
     

     
    <div class="next-design-link">
        <a href="../AAAI2022/">
            Related Papers in AAAI 2022 (2022.2.22)
            <i style="font-size:16px;" class="fa fa-arrow-right" aria-hidden="true"></i>
        </a>
    </div>
 
</div> 
             
        </div>

    </div>
    <div class="col-2">
        <div class="d-none d-sm-none d-md-block sticky-top border-start">
             
    
        <div>
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#anomaly-detection-anomaly-outlier-out-of-distribution-one-class"><span class="toc-number">1.</span> <span class="toc-text">anomaly detection [anomaly, outlier, out-of-distribution, one-class]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Time-series"><span class="toc-number">2.</span> <span class="toc-text">Time series</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sequence-learning"><span class="toc-number">3.</span> <span class="toc-text">Sequence learning</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#interpretable-interpretability"><span class="toc-number"></span> <span class="toc-text">interpretable&#x2F;interpretability</span></a> 
        </div>
    
 

        </div>
    </div>
</div>
</div>
 
    </main>

    <!-- 底部栏 -->
    <footer class="bg-dark pt-1 pb-0 mt-5">
    <div class="container pb-3 pt-3 text-center">
        <p class="text-muted tag-hover">
            Powered by 
             <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://hexo.io">
                 Hexo.io
            </a> &  <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://github.com/smile-yan/hexo-theme-heyan">
               heyan
            </a>
            <br>
        </p>
    </div>
</footer>
</body> 
</html>