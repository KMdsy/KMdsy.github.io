
<!DOCTYPE html>
<html>
<head>
    <title> Here is Shaoyu </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="/fish.png">
    <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">
    <link href="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
    <script src="https://cdn.staticfile.org/twitter-bootstrap/5.1.1/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
    
<link rel="stylesheet" href="../../../css/prism.css">
 
    
<script src="../../../js/prism.js"></script>

    
    
<link rel="stylesheet" href="../../../css/index.css">
 
    
<script src="../../../js/search.js"></script>



     
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
        </script>
     

     
        <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"> </script>
        
<script src="../../../js/fancybox.js"></script>

    

    <script type="text/javascript">
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
        var path = "/" + search_path;
        searchFunc(path, 'local-search-input', 'local-search-result');
    </script>
<meta name="generator" content="Hexo 5.4.2"></head>
 
 
<body>
    <!-- 导航栏 -->
    <!-- 导航栏 -->
<nav class="navbar navbar-expand-md navbar-dark bg-dark mb-4 pt-2 pb-2">
    <div class="container">
        <!-- 标题 --> 
        <a class="navbar-brand navbar-expand-sm" href="/">
            <img class="nofancybox" src="/shark.svg" style="width: 65px;">
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <!-- 左边右边导航按钮 --> 
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto">
                <!-- 左右两侧的导航栏 -->

 
 

    <li class="nav-item">
        <a class="nav-link" href="../../../">
           <big> <i class="fa fa-home ps-1" ></i> Home</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../note">
           <big> <i class="fa fa-file-text-o ps-1" ></i> Notes</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../survey">
           <big> <i class="fa fa-globe ps-1" ></i> Surveys</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../paperlist">
           <big> <i class="fa fa-cc-discover ps-1" ></i> Paper Lists</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../archives">
           <big> <i class="fa fa-archive ps-1" ></i> Archives</big>
        </a>
    </li>

    <li class="nav-item">
        <a class="nav-link" href="../../../about">
           <big> <i class="fa fa-user ps-1" ></i> About</big>
        </a>
    </li>
 
 
            </ul>

            
            <form class="">
                <div class="d-flex">
                    <button class="btn text-muted fa fa-search d-none d-md-block d-lg-block" disabled></button>
                    <input id="local-search-input" class="form-control me-2 pe-4" type="search"
                            placeholder="搜索 " aria-label="Search">
                </div>
                <div id="local-search-result" style="position:absolute; padding-top: 8px; max-height: 960px; width: 480px;overflow-y: scroll; z-index: 1050;"></div>
            </form>
            
            <ul class="navbar-nav">
                <!-- 左右两侧的导航栏 -->

 
 
            </ul>
        </div>
    </div>
</nav>


    <main class="container">
        
<div class="container-fluid markdown-section">
<div class="row">
    <div class="col-md-2 d-none d-sm-none d-md-block">
        <div class="">
            <!-- 同一类型的文件 -->
<!-- 尽可能做到每篇文章只有一个类
    1. 获得 post 的类别 categories
     2.1 如果 categories.length === 0，啥也不做
     2.2 如果 categories === 1，渲染这个类的所有文章
     2.3 如果 categories.length > 1 ，则以第一个类为准渲染所有文章
-->


 
        </div>
    </div>
    <div class="col-md-8 col-sm-12">
        <!-- 博客详情 -->
        <div class="">
            <!-- ps-4 pe-4 pt-2 -->
            <p class="h2">
                <span class="post-title">
                    Related Papers in AAAI 2020 (2020.02.07)
                </span>   
            </p>

            <div class="pb-3 pt-1 pe-3">
                <i class="fa fa-calendar p-1"></i>
                2020/02/07 00:00:00 

                <i class="fa fa-pencil"> </i>
                2022/04/12 16:30:28 

                <!--
                <i class="fa fa-folder-open p-1"> </i> 
                <span class="tag-hover">
                     
                </span>
                -->

                <i class="fa fa-tags p-1"> </i>
                <span class="tag-hover">
                    
                        <a href="../../../tags/paper-list/" class="link-dark text-decoration-none"> 
                            paper list 
                        </a>
                    
                </span>
            </div>

            <div class="border-bottom pb-2">
                <p><a target="_blank" rel="noopener" href="https://aaai.org/Conferences/AAAI-20/wp-content/uploads/2020/01/AAAI-20-Accepted-Paper-List.pdf">Link</a></p>
<span id="more"></span>

<h2 id="Time-Series"><a href="#Time-Series" class="headerlink" title="Time Series"></a>Time Series</h2><ul>
<li><p><strong>已读</strong> DATA-GRU: Dual-Attention Time-Aware Gated Recurrent Unit for Irregular Multivariate Time Series</p>
<p>Qingxiong Tan (Department of Computer Science, Hong Kong Baptist University)*; Mang YE (Inception Institute of<br>Artificial Intelligence); Baoyao Yang (Department of Computer Science, Hong Kong Baptist University); Siqi Liu<br>(Department of Computer Science, Hong Kong Baptist University); Andy Jinhua Ma (School of Data and Computer<br>Science, Sun Yat-Sen University); Terry Cheuk-Fung Yip (Department of Medicine and Therapeutics, The Chinese<br>University of Hong Kong); Grace Lai-Hung Wong (Department of Medicine and Therapeutics, The Chinese<br>University of Hong Kong); PongChi Yuen (Department of Computer Science, Hong Kong Baptist University)</p>
</li>
<li><p>Joint Modeling of Local and Global Temporal Dynamics for Multivariate Time Series Forecasting with Missing Values</p>
<p>Xianfeng Tang (The Pennsylvania State University)*; Huaxiu Yao (Pennsylvania State University); Yiwei Sun (Penn<br>State University); Charu Aggarwal (IBM); Prasenjit Mitra (Pennsylvania State University ); Suhang Wang<br>(Pennsylvania State University)</p>
</li>
<li><p>Factorized Inference in Deep Markov Models for Incomplete Multimodal Time Series</p>
<p>Tan Zhi-Xuan (Massachusetts Institute of Technology)*; Desmond Ong (A*STAR Artificial Intelligence Initiative);<br>Harold Soh (National University of Singapore)</p>
</li>
<li><p>A Variational Point Process Approach for Social Event Sequences</p>
<p>Zhen Pan (University of Science and Technology of China)*; Zhenya Huang (University of Science and Technology of<br>China ); Defu Lian (University of Science and Technology of China); Enhong Chen (University of Science and<br>Technology of China)</p>
</li>
<li><p>Deep Unsupervised Binary Coding Networks for Multivariate Time Series Retrieval</p>
<p>Dixian Zhu (University of Iowa); Dongjin Song (NEC Labs America)*; Yuncong Chen (NEC Laboratories America,<br>Inc.); Cristian Lumezanu (NEC Labs); Wei Cheng (NEC Laboratories America); Bo Zong (NEC Labs); Jingchao Ni ( NEC<br>Laboratories America); Takehiko Mizoguchi (NEC Laboratories America, Inc.); Tianbao Yang (University of Iowa);<br>Haifeng Chen (NEC Labs)</p>
</li>
<li><p>Relation Inference among Sensor Time Series in Smart Buildings with Metric Learning</p>
<p>Shuheng Li (Peking University)*; Dezhi Hong (UC San Diego); Hongning Wang (University of Virginia)</p>
</li>
<li><p>Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets</p>
<p>Ziqiang Cheng (Zhejiang University); Yang Yang (Zhejiang University)*; Wei Wang (State Grid Huzhou Power Supply<br>Co. Ltd.); Wenjie Hu (Zhejiang University); Yueting Zhuang (Zhejiang University); guojie song (PKU, China)</p>
</li>
</ul>
<ul>
<li><p>OMuLeT: Online Multi-Lead Time Location Prediction for Hurricane Trajectory Forecasting</p>
<p>Ding Wang (Michigan State University)*; Boyang Liu (Michigan State University); Pang-Ning Tan (MSU); Lifeng Luo<br>(Michigan State University)</p>
</li>
<li><p>Tensorized LSTM with Adaptive Shared Memory for Learning Trends in Multivariate Time Series</p>
<p>Dongkuan Xu (The Pennsylvania State University)*; Wei Cheng (NEC Laboratories America); Bo Zong (NEC Labs);<br>Dongjin Song (NEC Labs America); Jingchao Ni ( NEC Laboratories America); Wenchao Yu (UCLA); Yanchi Liu<br>(Rutgers); Haifeng Chen (NEC Labs); Xiang Zhang (The Pennsylvania State University)</p>
</li>
<li><p>Block Hankel Tensor ARIMA for Multiple Short Time Series Forecasting</p>
<p>QIQUAN SHI (Huawei Noah’s Ark Lab)*; Jiaming YIN (Tongji University); Jiajun CAI (The University of Hong Kong);<br>Andrzej Cichocki (Skolkovo Institute of Science and Technology); Tatsuya Yokota (Nagoya Institute of Technology);<br>Lei CHEN (Huawei Noah’s Ark Lab); Mingxuan Yuan (Huawei); Jia Zeng (Huawei Noah’s Ark Lab)</p>
</li>
<li><p>The Missing Data Encoder: Cross-Channel Image Completion with Hide-And-Seek Adversarial Network</p>
<p>Arnaud Dapogny (Pierre and Marie Curie University (UPMC))*; Matthieu Cord (Sorbonne University); Patrick Pérez<br>(Valeo.ai)</p>
</li>
</ul>
<ul>
<li><p>Joint Modeling of Local and Global Temporal Dynamics for Multivariate Time Series Forecasting with Missing<br>Values</p>
<p>Xianfeng Tang (The Pennsylvania State University)*; Huaxiu Yao (Pennsylvania State University); Yiwei Sun (Penn<br>State University); Charu Aggarwal (IBM); Prasenjit Mitra (Pennsylvania State University ); Suhang Wang<br>(Pennsylvania State University)</p>
</li>
</ul>
<h2 id="missing-value"><a href="#missing-value" class="headerlink" title="missing value"></a>missing value</h2><ul>
<li><p>Random Intersection Graphs and Missing Data</p>
<p>Dror Salti (Ben Gurion University of The Negev)*; Yakir Berchenko (Ben Gurion University of The Negev)</p>
</li>
</ul>
<ul>
<li><p>Polynomial Matrix Completion for Missing Data Imputation and Transductive Learning</p>
<p>Jicong Fan (Cornell University)*; Yuqian Zhang (Cornell University); Madeleine Udell (Cornell University)</p>
</li>
</ul>
<h2 id="Recurrent-Neural-Network"><a href="#Recurrent-Neural-Network" class="headerlink" title="Recurrent Neural Network"></a>Recurrent Neural Network</h2><ul>
<li><p>Eigenvalue Normalized Recurrent Neural Networks for Short Term Memory</p>
<p>Kyle Helfrich (University of Kentucky)*; Qiang Ye (University of Kentucky)</p>
</li>
<li><p>Particle Filter Recurrent Neural Networks</p>
<p>Xiao Ma (National University of Singapore)*; Peter Karkus (National University of Singapore); David Hsu (NUS);<br>Wee Sun Lee (National University of Singapore)</p>
</li>
<li><p>Segmenting Medical MRI via Recurrent Decoding Cell</p>
<p>Kai Xie (East China Normal University); 何良华 (同济大学); Ying Wen (East China Normal University)*</p>
</li>
<li><p>An Attentional Recurrent Neural Network for Personalized Next Location Recommendation</p>
<p>Qing Guo (Nanyang Technological University)*; Zhu Sun (Nanyang Technological University); Jie Zhang (Nanyang<br>Technological University); Yin-Leng Theng (Nanyang Technological University)</p>
</li>
<li><p>Weighted Automata Extraction from Recurrent Neural Networks via Regression on State Spaces</p>
<p>Takamasa Okudono (National Institute of Informatics)*; Masaki Waga (National Institute of Informatics); Taro<br>Sekiyama (National Institute of Informatics); Ichiro Hasuo (National Institute of Informatics &amp; SOKENDAI)</p>
</li>
<li><p>Recurrent Nested Model for Sequence Generation</p>
<p>Wenhao Jiang (Tencent AI Lab)*; Lin Ma (Tencent AI Lab); Wei Lu (UESTC)</p>
</li>
<li><p>Span-based Neural Buffer: Towards Efficient and Effective Utilization of Long-Distance Context for Neural Sequence Models</p>
<p>Yangming Li (Ant Financial Services Group)*; Kaisheng Yao (Ant Financial Services Group); Libo Qin (Research<br>Center for Social Computing and Information Retrieval, Harbin Institute of Technology); Shuang Peng (Ant Financial<br>Services Group); Yijia Liu (Alibaba Group); Xiaolong Li (Ant Financial)</p>
</li>
<li><p>Multi-Zone Unit for Recurrent Neural Networks</p>
<p>Fandong Meng (Tencent WeChat AI - Pattern Recognition Center Tencent Inc.)*; Jinchao Zhang (Tencent); Yang Liu<br>(Tsinghua University); Jie Zhou (Tencent)</p>
</li>
<li><p>Event-Driven Continuous Time Bayesian Networks</p>
<p>Debarun Bhattacharjya (IBM Research)*; Karthikeyan Shanmugam (IBM Research NY); Tian Gao (IBM Research);<br>Nicholas Mattei (Tulane University); Kush Varshney (IBM Research); Dharmashankar Subramanian (IBM Research)</p>
</li>
<li><p>Modeling Electrical Motor Dynamics using Encoder-Decoder with Recurrent Skip Connection</p>
<p>Sagar Verma (IIIT Delhi)*; Nicolas Henwood (Schneider Electric); Marc Castella (Telecom SudParis); Francois<br>Malrait (Schneider Electric); Jean-Christophe Pesquet (CentraleSupelec)</p>
</li>
<li><p>Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples</p>
<p>Minhao Cheng (UCLA)*; Jinfeng Yi (JD AI Research); Pin-Yu Chen (IBM Research); Huan Zhang (UCLA); Cho-Jui Hsieh (UCLA)</p>
</li>
<li><p>Temporal Pyramid Recurrent Neural Network</p>
<p>Qianli Ma (South China University of Technology)*; Zhenxi Lin (South China University of Technology); Enhuan<br>Chen (South China University of Technology); Garrison Cottrell (UC San Diego)</p>
</li>
<li><p>AirNet: A Calibration Model for Low-Cost Air Monitoring Sensors Using Dual Sequence Encoder Networks</p>
<p>Haomin Yu (Beijing Jiaotong University); Qingyong Li (Beijing Jiaotong University)*; YangLi-ao Geng (Beijing<br>Jiaotong University); Yingjun Zhang (Beijing Jiaotong University); Zhi Wei (New Jersey Institute of Technology)</p>
</li>
<li><p>A Skip-connected Evolving Recurrent Neural Network for Data Stream Classification under Label Latency Scenario</p>
<p>Monidipa Das (Nanyang Technological University); Mahardhika Pratama (Nanyang Technology University)*; Jie<br>Zhang (Nanyang Technological University); Yew Soon Ong (Nanyang Technological University, Nanyang View,<br>Singapore)</p>
</li>
<li><p><strong>已读</strong> Not All Attention Is Needed: Gated Attention Network for Sequence Data</p>
<p>LANQING XUE (Hong Kong University of Science and Technology)*; Xiaopeng Li (Hong Kong U. of Sci. &amp; Tech.);<br>Nevin Zhang (HKUST)</p>
</li>
<li><p>Biologically Plausible Sequence Learning with Spiking Neural Networks</p>
<p>Zuozhu Liu (Singapore University of Technology and Design); Thiparat Chotibut (Chulalongkorn university)*;<br>Christopher Hillar (Rewwood Center); Shaowei Lin (SUTD)</p>
</li>
<li><p>Structured Sparsification of Gated Recurrent Neural Networks</p>
<p>Ekaterina Lobacheva (Samsung-HSE Laboratory, National Research University Higher School of Economics)*;<br>Nadezhda Chirkova (Samsung-HSE Laboratory, National Research University Higher School of Economics);<br>Aleksandr Markovich (National Research University Higher School of Economics); Dmitry Vetrov (National Research<br>University Higher School of Economics, Samsung AI Center Moscow)</p>
</li>
<li><p>TapNet: Multivariate Time Series Classificationwith Attentional Prototype Network</p>
<p>Xuchao Zhang (Virginia Tech)*; Yifeng Gao (George Mason University); Jessica Lin (George Mason University);<br>Chang-Tien Lu (Virginia Tech, USA)</p>
</li>
</ul>
<h2 id="Anomaly-Detection"><a href="#Anomaly-Detection" class="headerlink" title="Anomaly Detection"></a>Anomaly Detection</h2><ul>
<li><p>Likelihood Ratios and Generative Classifiers for Unsupervised Out-of-Domain Detection In Task Oriented<br>Dialog</p>
<p>Varun Prashant Gangal (Carnegie Mellon University)*; Abhinav Arora (Facebook); Arash Einolghozati (Facebook);<br>Sonal Gupta (Facebook)</p>
</li>
<li><p>Self-Supervised Learning for Generalizable Out-of-Distribution Detection</p>
<p>Sina Mohseni (Texas A&amp;M University)*; Mandar Pitale (NVIDIA); JBS Yadawa (NVIDIA); Zhangyang Wang (TAMU)</p>
<p>解决的问题：主任务为有监督的out-of-distribution detection，于此同时要解决OOD detection问题，例子：在一个分类动物的问题上，要拒绝对一个人像进行识别，即不提供任何网络输出。</p>
<p>方法：一个两阶段的训练方法：</p>
<ol>
<li>先训练一个C类分类器用于分类原始任务（即动物分类问题，C为动物类别）</li>
<li>再在已经训练后的分类器的最后一层添加新的K类分类层，用于做OOD detection，其中$K = C + A$，A为一个超参数，是OOD样本的总类别数（即假设OOD样本共有A个类别）。上述网络使用混合样本进行微调，其中混合样本是in- 和out- of distribution 样本的混合。OOD样本在训练的时候可以设置为任意的OOD（即，对于一个原始问题为猫狗分类的网络，OOD_train可以设置为人脸，即使在真实世界中的OOD样本不止有人脸）。上述训练方法的目标是：<strong>让网络能够在不忘记in-distribution样本特征的情况下，还能记住OOD的一部分特征。</strong></li>
<li>在推理的时候，使用步骤<strong>2</strong>的分类层，即K类的分类层。对于任意一个测试样本，首先计算在C类分类问题上的预测结果，即$y_{pred} = arg_{max_i}{\gamma[1:C]}$，让后计算其OOD score，$Score_{OOD} = sum(\gamma[C:K])$，即在A类OOD分类上的SOFTMAX响应总和。</li>
<li>个人理解：OOD样本将在C:K上有较高的响应，此时该样本的$y_{pred}$将不可信，并拒绝该样本的分类。反之则接受该样本的分类。</li>
</ol>
</li>
<li><p>Adaptive Double Exploration Tradeoff for Outlier Detection</p>
<p>Xiaojin Zhang (CUHK)*; Honglei Zhuang (Google Research); Shengyu Zhang (Tencent); Yuan Zhou (UIUC)</p>
</li>
<li><p>MixedAD: A Scalable Algorithm for Detecting Mixed Anomalies in Attributed Graphs</p>
<p>Mengxiao Zhu (Beihang Univerisity)*; Haogang Zhu (Beihang University)</p>
</li>
<li><p>Detecting semantic anomalies</p>
<p>Faruk Ahmed (Mila, Universite de Montreal)*; Aaron Courville (Universite de Montreal)</p>
</li>
<li><p><strong>已读</strong> Outlier Detection Ensemble with Embedded Feature Selection</p>
<p>Li Cheng (National University of Defense Technology)*; Yijie Wang (“ National University of Defense Technology,<br>China”); Xinwang Liu (National University of Defense Technology); Bin Li ( National University of Defense<br>Technology)</p>
</li>
<li><p>Multi-scale Anomaly Detection on Attributed Networks</p>
<p>Leonardo Gutierrez Gomez (Universite catholique de Louvain)*; Alexandre Bovet (Universite catholique de<br>Louvain); Jean-Charles Delvenne (Universite catholique de Louvain)</p>
</li>
<li><p>Transfer Learning for Anomaly Detection through Localized and Unsupervised Instance Selection</p>
<p>Vincent Vercruyssen (KU Leuven)*; Jesse Davis (KU Leuven); Wannes Meert (KU Leuven)</p>
</li>
<li><p>MIDAS: Microcluster-Based Detector of Anomalies in Edge Streams</p>
<p>Siddharth Bhatia (National University of Singapore)*; Bryan Hooi (National University of Singapore); Minji Yoon<br>(Carnegie Mellon University); Kijung Shin (KAIST); Christos Faloutsos ()</p>
</li>
</ul>
<h2 id="Sequence"><a href="#Sequence" class="headerlink" title="Sequence"></a>Sequence</h2><ul>
<li><p>Graph Transformer for Graph-to-Sequence Learning</p>
<p>Deng Cai (The Chinese University of Hong Kong)*; Wai Lam (The Chinese University of Hong Kong)</p>
</li>
<li><p>Sequence Generation with Optimal-Transport-Enhanced Reinforcement Learning</p>
<p>Liqun Chen (Duke University)*; Ke Bai (Duke University); Chenyang Tao (Duke University); Yizhe Zhang (Microsoft<br>Research); Guoyin Wang (Duke University); Wenlin Wang (Duke Univeristy); Ricardo Henao (Duke University);<br>Lawrence Carin Duke (CS)</p>
</li>
</ul>
<h2 id="Interpretable"><a href="#Interpretable" class="headerlink" title="Interpretable"></a>Interpretable</h2><ul>
<li><p>Dynamic Network Pruning with Interpretable Layerwise Channel Selection</p>
<p>Yulong Wang (Tsinghua University); Xiaolu Zhang (Ant Financial Services Group); Hang Su (Tsinghua Univiersity); Bo<br>Zhang (Tsinghua University); Xiaolin Hu (Tsinghua University)*</p>
</li>
<li><p>Interpretable and Differentially Private Predictions</p>
<p>Frederik Harder (Max Planck Institute)*; Matthias Bauer (MPI Tübingen); Mijung Park (MPI Tuebingen)</p>
</li>
<li><p>MRI Reconstruction with Interpretable Pixel-Wise Operations Using Reinforcement Learning</p>
<p>wentian li (Tsinghua University)*; XIDONG FENG (department of Automation,Tsinghua University); Haotian An<br>(Tsinghua University); Xiang Yao Ng (Tsinghua University); Yu-Jin Zhang (Tsinghua University)</p>
</li>
<li><p>Interpretable rumor detection in microblogs by attending to user interactions</p>
<p>Serena Khoo (DSO National Laboratories)*; Hai Leong Chieu (DSO National Laboratories); Zhong Qian (Soochow<br>University); Jing Jiang (Singapore Management University)</p>
</li>
<li><p>Asymmetrical Hierarchical Networks with Attentive Interactions for Interpretable Review-Based Recommendation</p>
<p>Xin Dong (Rutgers University); Jingchao Ni ( NEC Laboratories America)*; Wei Cheng (NEC Laboratories America);<br>Zhengzhang Chen (NEC Laboratories America, Inc.); Bo Zong (NEC Labs); Dongjin Song (NEC Labs America); Yanchi<br>Liu (NEC Labs America); Haifeng Chen (NEC Labs); Gerard de Melo (Rutgers University)</p>
</li>
<li><p>Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction</p>
<p>Haoxi Zhong (Tsinghua University)*; Yuzhong Wang (Tsinghua University); Cunchao Tu (Tsinghua University);<br>Tianyang Zhang (Powerlaw); Zhiyuan Liu (Tsinghua University); Maosong Sun (Tsinghua University)</p>
</li>
<li><p>Chemically Interpretable Graph Interaction Network for Prediction of Pharmacokinetic Properties of Drug-<br>like Molecules</p>
<p>Yashaswi Pathak (International Institute of Information Technology,Hyderabad); Siddhartha Laghuvarapu (IIIT<br>Hyderabad); Sarvesh Mehta (IIIT Hyderabad); Deva Priyakumar (IIIT Hyderabad)*</p>
</li>
<li><p>Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents</p>
<p>Ming Tu (JD AI Research)*; Kevin Huang (JD AI Research); Guangtao Wang (JD.com); Jing Huang (JD.COM);<br>Xiaodong He (JD AI Research); Bowen Zhou (JD)</p>
</li>
</ul>
<h2 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h2><ul>
<li><p>General Partial Label Learning via Dual Bipartite Graph Autoencoder</p>
<p>Brian Chen (Columbia University); Bo Wu (Columbia University); Alireza Zareian (Columbia University); Hanwang<br>Zhang (Nanyang Technological University); Shih-Fu Chang (Columbia University)*</p>
</li>
<li><p>A Variational Autoencoder with Deep Embedding Model for Generalized Zero-Shot Learning</p>
<p>Peirong Ma (Guangzhou University); Xiao Hu (Guangzhou University)*</p>
</li>
</ul>
<ul>
<li> Graph Representation Learning via Ladder Gamma Variational Autoencoders</li>
</ul>
<p>  Arindam Sarkar (Amazon)*; Nikhil Mehta (Duke University); Piyush Rai (IIT Kanpur)</p>
<ul>
<li><p>Semi-Supervised Text Simplification with Back-Translation and Asymmetric Denoising Autoencoders</p>
<p>Yanbin Zhao (Shanghai Jiao Tong University)*; Lu Chen (Shanghai Jiao Tong University); Zhi Chen (Shanghai Jiao<br>Tong University); Kai Yu (Shanghai Jiao Tong University)</p>
</li>
<li><p>Draft and Edit: Automatic Storytelling Through Multi-Pass Hierarchical Conditional Variational Autoencoder</p>
<p>Meng Hsuan Yu (Peking University )*; Juntao Li (Peking University); Danyang Liu (Shanghai Jiao Tong University);<br>Bo Tang (Southern University of Science and Technology); Haisong Zhang (Tencent AI Lab); Dongyan Zhao (Peking<br>University); Rui Yan (Peking University)</p>
</li>
<li><p>Vector Quantization-Based Regularization for Autoencoders</p>
<p>Hanwei Wu (KTH Royal Institute of Technology)*; Markus Flierl (KTH Royal Institute of Technology)</p>
</li>
</ul>
<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><ul>
<li><p>SalSAC: A Video Saliency Prediction Model with Shuffled Attentions and Correlation-based ConvLSTM</p>
<p>Xinyi Wu (University of South Carolina); Zhenyao Wu (University of South Carolina); jinglin zhang (Nanjing<br>University of Information Science and Technology); Lili Ju (University of South Carolina); Song Wang (University of<br>South Carolina)*</p>
</li>
<li><p>Graph LSTM with Context-Gated Mechanism for Spoken Language Understanding</p>
<p>Linhao Zhang (Peking University)*; Dehong Ma (Peking University); Xiaodong Zhang (Peking University); Xiaohui<br>Yan (Huawei Technologies); Houfeng Wang (Peking University)</p>
</li>
<li><p>Self-Attention ConvLSTM for Spatiotemporal Prediction</p>
<p>Zhihui Lin (Tsinghua University)*; Maomao Li (Tsinghua university); Zhuobin Zheng ( Tsinghua University);<br>Yangyang Cheng (Tsinghua University); Chun Yuan (Tsinghua University)</p>
</li>
<li><p>Bivariate Beta-LSTM</p>
<p>Kyungwoo Song (KAIST)*; JoonHo Jang (KAIST); Seung jae Shin (KAIST); Il-Chul Moon (KAIST)</p>
</li>
<li><p>D2D-LSTM: LSTM-based Path Prediction of Content Diffusion Tree in Device-to-Device Social Networks</p>
<p>Heng Zhang (Tianjin University)*; Xiaofei Wang (College of Intelligence and Computing，Tianjin University); Jiawen<br>Chen (Tianjin University); Chenyang Wang (Tianjin University); Jianxin Li (Deakin University)</p>
</li>
<li><p>Why Attention? Analyze BiLSTM Deficiency and Its Remedies in the Case of NER</p>
<p>Peng-Hsuan Li (Academia Sinica)*; Tsu-Jui Fu (National Tsing Hua University); Wei-yun Ma (台湾中研院)</p>
</li>
<li><p>CF-LSTM: Cascaded Feature-Based Long Short-Term Networks for Predicting Pedestrian Trajectory</p>
<p>Yi Xu (Xi’an Jiaotong University); JING YANG (Xi’an Jiaotong University); Shaoyi Du (Xi’an Jiaotong Unviersity)*</p>
</li>
</ul>
<h2 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h2><ul>
<li><p>Random Erasing Data Augmentation</p>
<p>Zhun Zhong (Xiamen University)*; Liang Zheng (Australian National University); Guoliang Kang (CMU); Shaozi Li<br>(Xiamen University, China); Yi Yang (UTS)</p>
<p>论文为CNN训练提出了一种新的数据增强方法。Random Erasing，在一张图片中随机的选择一个矩形框，在随机的位置上使用随机的值来擦除图片原来的像素。通过该方法能够给图片加入不同程度的遮挡，通过这样的训练数据，可以减少模型过拟合的风险同时对遮挡具有一定的鲁棒性。随机擦除和random cropping，random flipping一样可以作为数据增强的方法，在分类，检测和行人重识别领域能够取得不错的效果。</p>
</li>
<li><p>Effective Data Augmentation with Multi-Domain Learning GANs</p>
<p>Shin’ya Yamaguchi (NTT)*; Sekitoshi Kanai (NTT Software Innovation Center/Keio University); Takeharu Eda (NTT)</p>
</li>
</ul>
<ul>
<li><p>CONAN: Complementary Pattern Augmentation for Rare Disease Detection</p>
<p>Limeng Cui (Penn State University); Siddharth Biswal (Georgia Institute of Technology); Lucas Glass (IQVIA); Greg<br>Lever (IQVIA); Jimeng Sun (Georgia Tech); Cao Xiao (IQVIA)*</p>
<p>稀有疾病影响着全世界亿万人民，但由于它们的患病率极低（从1 / 1,000到1 / 200,000患者不等）并且被严重误诊，因此难以发现。我们如何可靠地检测出如此低的患病率？如何进一步利用诊断可能不确定的患者改善检测率？在本文中，我们提出了一种用于罕见病检测的互补模式增强（CONAN）框架。CONAN结合了对抗训练和最大利润率分类的思想。它首先学习自我专注和分层嵌入，以进行患者模式表征。然后，我们开发了互补的生成对抗网络（GAN）模型，通过鼓励各类别之间的最大差额来生成不确定患者的候选阳性和阴性样本。此外，CONAN具有疾病检测器，可在对抗性训练期间用作识别罕见疾病的识别器。我们在两项疾病检测任务上评估了CONAN。对于低流行性炎症性肠病（IBD）检测，CONAN曲线下的精确召回面积（PR-AUC）为0.96，相对于最佳基线，相对改善了50.1％。对于罕见疾病特发性肺纤维化（IPF）检测，CONAN达到0.22 PR-AUC，相对最佳基准，相对改善41.3％。</p>
</li>
<li><p>Nonlinear Mixup: Out-Of-Manifold Data Augmentation for Text Classification</p>
<p>Hongyu Guo (National Research Council Canada)*</p>
</li>
<li><p>Dialog State Tracking with Reinforced Data Augmentation</p>
<p>Yichun Yin (Noah’s Ark Lab of Huawei)*; Lifeng Shang (Noah’s Ark Lab); Xin Jiang (Huawei Noah’s Ark Lab); Xiao<br>Chen (Huawei Noah’s Ark Lab); Qun Liu (Huawei Noah’s Ark Lab)</p>
</li>
</ul>
<ul>
<li><p>Constructing Multiple Tasks for Augmentation: Improving Neural Image Classification With K-means Features</p>
<p>Tao Gui (Fudan University)*; Lizhi Qing (Fudan university); Qi Zhang (Fudan University); Jiacheng Ye (fudan<br>university); Hang Yan (Fudan University); zichu fei (FUDAN University); Xuanjing Huang (“ Fudan University, China”)</p>
</li>
</ul>
<ul>
<li><p>Incorporating Label Embedding and Feature Augmentation for Multi-Dimensional Classification</p>
<p>Haobo Wang (Zhejiang University)*; Chen Chen (Zhejiang University); Weiwei Liu (Wuhan University); Ke Chen (<br>Zhejiang University); Tianlei Hu (Zhejiang University); Gang Chen (Zhejiang University)</p>
<p>通过集成标签信息来操纵特征空间的特征增强是解决多维分类（MDC）问题的最流行策略之一。但是，香草特征增强方法无法考虑类内的排他性，并且可能会导致性能下降。为了填补这一空白，提出了一种基于神经网络的新型模型，该模型将标签嵌入和特征增强（LEFA）技术无缝集成以学习标签相关性。具体地，基于注意力分解机，引入了互相关感知网络以学习低维标签表示，其同时描绘了类间相关性和类内排他性。然后，可以将学习到的潜在标签矢量用于扩大原始特征空间。</p>
</li>
</ul>
 
            </div>
        </div>
        
        <div class="mt-3">
            <!-- 前一页后一页 -->
<div class="previous-next-links">
     
    <div class="previous-design-link">
        <a href="../../notes/nature/">
            <i style="font-size:16px;" class="fa fa-arrow-left" aria-hidden="true"></i>
            如何在科学会议作报告
        </a>
    </div>
     

     
    <div class="next-design-link">
        <a href="../IJCAI2020/">
            Related Papers in IJCAI 2020 (2021.01)
            <i style="font-size:16px;" class="fa fa-arrow-right" aria-hidden="true"></i>
        </a>
    </div>
 
</div> 
             
        </div>

    </div>
    <div class="col-2">
        <div class="d-none d-sm-none d-md-block sticky-top border-start">
             
    
        <div>
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Time-Series"><span class="toc-number">1.</span> <span class="toc-text">Time Series</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#missing-value"><span class="toc-number">2.</span> <span class="toc-text">missing value</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recurrent-Neural-Network"><span class="toc-number">3.</span> <span class="toc-text">Recurrent Neural Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Anomaly-Detection"><span class="toc-number">4.</span> <span class="toc-text">Anomaly Detection</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sequence"><span class="toc-number">5.</span> <span class="toc-text">Sequence</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Interpretable"><span class="toc-number">6.</span> <span class="toc-text">Interpretable</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Autoencoder"><span class="toc-number">7.</span> <span class="toc-text">Autoencoder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LSTM"><span class="toc-number">8.</span> <span class="toc-text">LSTM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-augmentation"><span class="toc-number">9.</span> <span class="toc-text">Data augmentation</span></a></li></ol> 
        </div>
    
 

        </div>
    </div>
</div>
</div>
 
    </main>

    <!-- 底部栏 -->
    <footer class="bg-dark pt-1 pb-0 mt-5">
    <div class="container pb-3 pt-3 text-center">
        <p class="text-muted tag-hover">
            Powered by 
             <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://hexo.io">
                 Hexo.io
            </a> &  <a class="link-secondary text-decoration-none" target="_blank" rel="noopener" href="https://github.com/smile-yan/hexo-theme-heyan">
               heyan
            </a>
            <br>
        </p>
    </div>
</footer>
</body> 
</html>